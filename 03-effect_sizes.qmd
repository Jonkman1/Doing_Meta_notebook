# Effect Sizes

## Theory

Effect size is defined here as a metric quantifying the relationship between two entities. It captures the **direction** and **magnitude** of this relationship. If relationships are expressed as the same effect size, it is possible to compare them.Effect sizes are the building blocks of meta-analyses.

To perform a meta-analysis, we need at least an estimate of the effect size and its standard error. They should be comparable, computable, reliable and interpretable. The standard error of an effect size represents how precise the study’s estimate of the effect is. Meta-analysis gives effect sizes with a greater precision a higher weight because they are better estimators of the true effect.

There are various effect sizes we can use in meta-analyses. Common ones are “one-variable” relationship measures, such as: - means (summing all individual values deviding by sum of sample size);\
- proportions (number of individuals falling into a specific subgroup deviding by total number of individuals);\
- correlations (expresses teh amount of co-variation between two variables, for example the Pearson Product-Moment Correlation and Point-Biserial Correlation);\
- (standardized) mean differences (difference in means between two independent groups deviding by the pooled standard deviation); - risk ratio (relative risk) as the ratio of two risks; - odds ratio, as the number of cases which fall into a specific subgroup deviding by the number of cases which do not fall into that subgroup. - incidence rate ratios (also called rate ratio), takes into account the person/time-aspects of two groups.

Effect sizes can also be biased, for example by measurement error and range restriction. There are formulas to correct for some biases, including the small sample bias of standardized mean differences, attenuation due to unreliability, as well as range restriction problems. Other common problems are that studies report the data needed to calculate effect sizes in different formats, as well as the unit-of-analysis problem, which arises when studies contribute more than one effect size.

## Practice

Let us look first at the bewteen-group standardized mean difference (SMD) effect size. It is used when the outcome is continuous and the predictor is categorical. It is the difference in means between two independent groups deviding by the pooled standard deviation. It is also called Cohen’s d.

$$SMD_{between} = \frac{\bar{X}_1 - \bar{X}_2}{s_p}$$

where $\bar{X}_1$ and $\bar{X}_2$ are the means of the two groups and $s_p$ is the pooled standard deviation. SMD's are often interpreted as small (0.2), medium (0.5) and large (0.8) effects.

There are several functions in R which allow us to calculate SMDbetween/Cohen’s `d` in one step. Here, we use the `esc_mean_sd` function, which is part of the `esc`-package. We have not used this package before, so it is necessary to install it first.

```{r}
# install.packages("esc")
library(esc)

# Define the data we need to calculate SMD/d
# This is just some example data that we made up
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

# Calculate effect size
esc_mean_sd(grp1m = grp1m, grp2m = grp2m, 
            grp1sd = grp1sd, grp2sd = grp2sd, 
            grp1n = grp1n, grp2n = grp2n)


```

To conduct a meta-analysis of standardized mean differences, our data set should at least contain the following columns:

-   **n.e.** The number of observations in the intervention/experimental group.
-   **mean.e.** The mean of the intervention/experimental group.
-   **sd.e.** The standard deviation in the intervention/experimental group.
-   **n.c.** The number of observations in the control group.
-   **mean.c.** The mean of the control group.
-   **sd.c.** The standard deviation in the control group.

For binary outcomes **odds ratios** can be used. The `esc_2x2` function in the `esc` package provides an easy way to calculate the (log) odds ratio in R.

```{r}
library(esc)

# Define data
grp1yes <- 45  # events in the treatment group
grp1no <- 98   # non-events in the treatment group
grp2yes <- 67  # events in the control group
grp2no <- 76   # non-events in the control group

# Calculate OR by setting es.type to "or"
esc_2x2(grp1yes = grp1yes, grp1no = grp1no,
        grp2yes = grp2yes, grp2no = grp2no,
        es.type = "or")
```

To conduct a meta-analysis of odds ratios in R, the following columns should be included in our data set:

-   **event.e.** The number of events in the treatment or experimental group.\
-   **n.e.** The sample size of the treatment or experimental group.\
-   **event.c.** The number of events in the control group.\
-   **n.c.** The sample size of the control group.

For a practice sample for correction we look at small sample correction. We can easily convert unstandardized SMDs/Cohen’s `d`to Hedges’ `g` using the `hedges_g` function in the `esc`-package.

```{r}
# Load esc package
library(esc)

# Define uncorrected SMD and sample size n
SMD <- 0.5
n <- 30

# Convert to Hedges g
g <- hedges_g(SMD, n)
g
```
