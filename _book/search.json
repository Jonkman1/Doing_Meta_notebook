[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notitieboekje dat hoort bij Doing Meta-Analysis with R. A Hands-On Guide",
    "section": "",
    "text": "Voorwoord\nDit is mijn notitieboekje dat hoort bij Doing Meta-Analysis with R dat Mathias Harrer, Pim Cuijpers, Toshi Furukawa, and David Ebert schreven. Dat boek van Harrer en anderen is een open source boek dat je kunt vinden op https://doingmetaanalysis.github.io. Omdat ik de komende maanden een groep studenten begeleid bij het maken van een masterthesis, waarbij ze de techniek van meta-analyse gebruiken, heb ik dit gemaakt om hen goed bij het uitvoeren van hun activiteiten te ondersteunen.\n\n\n\nHet boek"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "01-introductie.html",
    "href": "01-introductie.html",
    "title": "1  Introductie",
    "section": "",
    "text": "Met die grote hoeveelheden onderzoeksresultaten die elke dag worden geproduceerd, is het nog belangrijker geworden om het bewijsmateriaal in zijn geheel te bekijken en het kritisch te beoordelen. Meta-analyse kan hierbij enorm helpen, zolang de beperkingen en vooroordelen ervan worden erkend. Het doel van meta-analyse is om al het beschikbare bewijsmateriaal met betrekking tot een duidelijk gedefinieerd onderzoeksgebied of onderzoeksvraag te combineren, dat samen te vatten en uiteindelijk te interpreteren. Er zijn ten minste drie verschillende manieren waarop bewijs uit meerdere onderzoeken kan worden samengevoegd:\n\nTraditionele/narratieve reviews (geschreven door experts en autoriteiten in het veld zonder duidelijke regels).\n\nSystematische reviews (om bewijs samen te vatten met behulp van duidelijk gedefinieerde en transparante regels).\n\nMeta-analyses (om bewijs te combineren en samen te vatten over alle onderzoeken met behulp van duidelijk gedefinieerde en transparante regels op kwantitatieve wijze).\n\n\nMeta-analyse is niet uitgevonden door één persoon alleen, maar kent vele grondleggers en vaders. De eerste pogingen om de effecten van afzonderlijke, maar vergelijkbare onderzoeken statistisch samen te vatten, dateren van ongeveer 100 jaar geleden. Talloze innovaties hebben de toepasbaarheid, robuustheid en veelzijdigheid van de meta-analytische methoden in de laatste vier decennia vergroot. In die periode is meta-analyse een universeel geaccepteerd onderzoeksinstrument geworden. Er zijn veel valkuilen en het boek leidt ons langs veelvoorkomende valkuilen in de uitvoering van meta-analyse. Hier worden er vier genoemd:\n\n\nHet “Appels en Sinaasappelen” probleem: Je zou kunnen stellen dat meta-analyse appels met peren combineren is. De reikwijdte en specificiteit van een meta-analyse moet daarom gebaseerd zijn op de onderzoeksvraag die beantwoord moet worden, en deze vraag moet van praktisch belang zijn. Variatie tussen studies kan onproblematisch zijn, zelfs inzichtgevend, als die op de juiste manier wordt opgenomen in de doelen en probleemspecificatie van een meta-analyse.\n\nHet “Vuiligheid Erin, Vuiligheid Eruit”-probleem: De kwaliteit van het bewijs dat een meta-analyse oplevert, hangt sterk af van de kwaliteit van de studies die erin worden samengevat. Anders krijg je “vuiligheid erin, vuiligheid eruit”.\n\nHet “Dossierlader”-probleem: Het dossierladerprobleem verwijst naar het probleem dat niet alle relevante onderzoeksresultaten worden gepubliceerd. Negatieve of ‘teleurstellende’ resultaten zijn ondervertegenwoordigd. Daarom moet je kijken naar publicatiebias.\n\nHet “agenda van de onderzoeker”-probleem: Meta-analyse gaat gepaard met veel “vrijheidsgraden van de onderzoeker”, waardoor er veel ruimte overblijft voor beslissingen die soms willekeurig en soms het resultaat van geheime persoonlijke voorkeuren zijn. Een manier om het probleem van de agenda van de onderzoeker te verminderen, is het vooraf registreren en publiceren van een gedetailleerd analyseplan voordat met het verzamelen van gegevens voor een meta-analyse wordt begonnen.\n\n\nBelangrijk is dat de methodologische beslissingen zowel transparant als reproduceerbaar zijn. Hier worden de eerste bouwstenen gepresenteerd. Definieer de onderzoeksvraag: of een goede onderzoeksvraag te definiëren, helpt het om deze eerst te zien als een vorm van probleemspecificatie. Door jezelf stap voor stap deze vragen te stellen, zou het gemakkelijker moeten worden om te definiëren wat je wilt bereiken met je meta-analyse. Gebruik bijvoorbeeld het FINER-raamwerk (Feasible, Interesting, Novel, Ethical, Relevant) of PICO (Population, Intervention, Comparison, Outcome) om je onderzoeksvraag te definiëren.\nKijk verder ook naar in aanmerking komende onderzoeksdesigns, houd rekening met culturele en taalkundige verschillen tussen in aanmerking komende studies, en kijk naar publicatietype en de rol van grijze literatuur. Schrijf deze dingen in inclusie en uitsluitingscriteria. Houd bij dit alles rekening met de PRISMA- () en MARS- ()-richtlijnen. Veel van deze problemen kunnen worden verminderd door een duidelijke onderzoeksvraag en geschiktheidscriteria te definiëren, een analyseplan te schrijven, de meta-analyse vooraf te registreren en de studiezoektocht en gegevensextractie op een systematische en reproduceerbare manier uit te voeren."
  },
  {
    "objectID": "02-discovering_R.html",
    "href": "02-discovering_R.html",
    "title": "2  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "03-effect_sizes.html",
    "href": "03-effect_sizes.html",
    "title": "3  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "04-pooling_effect_sizes.html",
    "href": "04-pooling_effect_sizes.html",
    "title": "4  Effect Sizes samenbrengen",
    "section": "",
    "text": "Theory\nIn de statistiek wordt een model gezien als een vereenvoudigde “theorie”, die het proces beschrijft waarmee de waargenomen gegevens zijn gegenereerd. Vaak wordt het geschreven als een wiskundige formule om processen in de wereld om ons heen op een geïdealiseerde manier te beschrijven.\nEr zijn twee alternatieve modellen in de meta-analyse: het fixed-effect model en het random-effects model. Het fixed-effect model gaat ervan uit dat er één ware effectgrootte is en dat alle effectgroottes afkomstig zijn van één homogene populatie.\nHet random-effects model daarentegen stelt dat de ware effectgroottes ook variëren binnen meta-analyses. Het anticipeert op aanzienlijke heterogeniteit tussen studies in de ware effecten. Het doel van het random-effects model is daarom om het gemiddelde te vinden van de ware effectgrootteverdeling die ten grondslag ligt aan onze gegevens. De variantie van de ware effectgroottes \\(\\tau2\\), ook wel heterogeniteitsvariantie tussen studies genoemd, moet worden geschat in random-effects meta-analyses. Hier zijn verschillende methoden voor, en welke het beste werkt hangt af van de context.\nDe meest gebruikelijke manier om een gepoolde effectgrootte te berekenen is via de inverse-variantiemethode. In het meta-pakket is er een functie om meta-analyses uit te voeren van vooraf berekende effectgroottegegevens, evenals een reeks functies die kunnen worden gebruikt voor verschillende soorten “ruwe” uitkomstgegevens.\nPractijk\nEerst kijken we hoe we een fixed-model kunnen uitvoeren met het esc pakket:\n\n# Laad dmetar, esc en tidyverse\nlibrary(dmetar)    ## voor de data\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(esc)       ## voor de berekening van effect groottes \nlibrary(tidyverse) ## voor databewerking\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Laad de dataset via dmetar\ndata(SuicidePrevention)\n\n# Bekijk de dataset en zie welke variabelen (kolommen) en studies (rijen) er zijn\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nAls we dat weten kunnen we de dataset analyseren:\n\n# Bereken Hedges' g en de Standaard Fout (SE)\n# We slaan de studienamen op in \"study\".\n# We gebruiken de pmap_dfr functie om de effect grootte te berekenen voor elke rij studie.\n# Kijk goed wat we gebruiken\nSP_calc &lt;- pmap_dfr(SuicidePrevention, \n                    function(mean.e, sd.e, n.e, mean.c,\n                             sd.c, n.c, author, ...){\n                      esc_mean_sd(grp1m = mean.e,\n                                  grp1sd = sd.e,\n                                  grp1n = n.e,\n                                  grp2m = mean.c,\n                                  grp2sd = sd.c,\n                                  grp2n = n.c,\n                                  study = author,\n                                  es.type = \"g\") %&gt;% \n                        as.data.frame()}) \n\n# Laten we de nieuwe dataset opnieuw bekijken\n# Je ziet dat Hedges' g (\"es\") en standard error (\"se\") erin zit\nglimpse(SP_calc)\n\nRows: 9\nColumns: 9\n$ study       &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt …\n$ es          &lt;dbl&gt; -0.14279447, -0.60770928, -0.11117965, -0.12698011, -0.392…\n$ weight      &lt;dbl&gt; 46.09784, 34.77314, 14.97625, 32.18243, 24.52054, 54.50431…\n$ sample.size &lt;dbl&gt; 185, 146, 60, 129, 100, 220, 120, 80, 107\n$ se          &lt;dbl&gt; 0.1472854, 0.1695813, 0.2584036, 0.1762749, 0.2019459, 0.1…\n$ var         &lt;dbl&gt; 0.02169299, 0.02875783, 0.06677240, 0.03107286, 0.04078214…\n$ ci.lo       &lt;dbl&gt; -0.4314686, -0.9400826, -0.6176413, -0.4724727, -0.7882811…\n$ ci.hi       &lt;dbl&gt; 0.145879624, -0.275335960, 0.395282029, 0.218512440, 0.003…\n$ measure     &lt;chr&gt; \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\", \"g\"\n\n\nWe gebruiken deze resultaten om de formule van het fixed-effect model toe te passen:\n\n# Bereken de inverse variantie-gewichten voor elk onderzoek.\nSP_calc$w &lt;- 1/SP_calc$se^2\n\n# Vervolgens gebruiken we de gewichten om het gecombineerde effect te berekenen\npooled_effect &lt;- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)\npooled_effect\n\n[1] -0.2311121\n\n\nDe resultaten van onze berekeningen laten zien dat de gepoolde effectgrootte, uitgaande van een model met een vast effect, \\(g \\approx -0,23\\) is. Later laten we zien hoe het random model werkt.\nmetagen kan worden gebruikt voor vooraf berekende effectgroottegegevens. Hier wordt het gebruikt om een meta-analyse uit te voeren van de ThirdWave dataset. Laten we de dataset openen en bekijken.\n\nlibrary(tidyverse) # voor databewerking\nlibrary(dmetar)    # voor de data\nlibrary(meta)      # voor de meta-analyse\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\nNu gaan we voor de analyse het random-effect model gebruken via het pakket meta.\nTE bevat de \\(g\\) waarden en seTE de standaardfout ervan. De metagen functie neemt de volgende argumenten:\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\nOns m.gen object bevat nu alle resultaten van de meta-analyse. Een gemakkelijke manier om een overzicht te krijgen is door de summary functie te gebruiken.\n\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [0.3782; 0.7760] 6.12 &lt; 0.0001\n\nQuantifying heterogeneity:\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n\n\nHet gepoolde effect direct weergeven is ook mogelijk. Hier dat effect via random-methode\n\nm.gen$TE.random\n\n[1] 0.5771158\n\n\nHier dat effect via fixed-methode.\n\nm.gen$TE.fixed\n\n[1] 0.4805045\n\n\nJe kunt ook een sensitiviteis-analyse uitvoeren. Dan zet je een andere methode in om te zien of de resultaten dan hetzelfde zijn. We kunnen bijvoorbeeld de functie update.meta gebruiken om de methode voor het schatten van \\(\\tau^2\\) te veranderen van de standaard REML in PM (Paule-Mandel). Dit is een goed idee bijvoorbeeld als het aantal studies klein is.\n\nm.gen_update &lt;- update.meta(m.gen, \n                            method.tau = \"PM\")\n\n# effect\nm.gen_update$TE.random\n\n[1] 0.5873544\n\n\nOm de \\(\\tau^2\\) schatting te krijgen doe je:\n\nm.gen_update$tau2\n\n[1] 0.1104957\n\n\nNu iets over binaire uitkomsten. We gebruiken de functie metabin om een meta-analyse uit te voeren op de dataset DepressionMortality. Laten we de dataset openen en eerste eens bekijken.\n\nlibrary(dmetar)\nlibrary(tidyverse)\nlibrary(meta)\n\ndata(DepressionMortality)\nglimpse(DepressionMortality)\n\nRows: 18\nColumns: 6\n$ author  &lt;chr&gt; \"Aaroma et al., 1994\", \"Black et al., 1998\", \"Bruce et al., 19…\n$ event.e &lt;dbl&gt; 25, 65, 5, 26, 32, 1, 24, 15, 15, 173, 37, 41, 29, 61, 15, 21,…\n$ n.e     &lt;dbl&gt; 215, 588, 46, 67, 407, 44, 60, 61, 29, 1015, 105, 120, 258, 38…\n$ event.c &lt;dbl&gt; 171, 120, 107, 1168, 269, 87, 200, 437, 227, 250, 66, 9, 24, 3…\n$ n.c     &lt;dbl&gt; 3088, 1901, 2479, 3493, 6256, 1520, 882, 2603, 853, 3375, 409,…\n$ country &lt;chr&gt; \"Finland\", \"USA\", \"USA\", \"USA\", \"Sweden\", \"USA\", \"Canada\", \"Ne…\n\n\nIn dit voorbeeld wordt de risk ratio, RR(Risicoverhouding)) berekend (de binaire uitkomst). We gebruiken een random-effect poolingmodel en omdat we te maken hebben met binaire uitkomstgegevens, gebruiken we de Paule-Mandel-schatter voor \\(tau2\\).\n\nm.bin &lt;- metabin(event.e = event.e, \n                 n.e = n.e,\n                 event.c = event.c,\n                 n.c = n.c,\n                 studlab = author,\n                 data = DepressionMortality,\n                 sm = \"RR\",\n                 method = \"MH\",\n                 MH.exact = TRUE,\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"PM\",\n                 hakn = TRUE,\n                 title = \"Depressie en Mortaliteit\")\nsummary(m.bin)\n\nReview:     Depressie en Mortaliteit\n\n                          RR            95%-CI %W(random)\nAaroma et al., 1994   2.0998 [1.4128;  3.1208]        6.0\nBlack et al., 1998    1.7512 [1.3139;  2.3341]        6.6\nBruce et al., 1989    2.5183 [1.0785;  5.8802]        3.7\nBruce et al., 1994    1.1605 [0.8560;  1.5733]        6.5\nEnzell et al., 1984   1.8285 [1.2853;  2.6014]        6.3\nFredman et al., 1989  0.3971 [0.0566;  2.7861]        1.2\nMurphy et al., 1987   1.7640 [1.2644;  2.4610]        6.4\nPenninx et al., 1999  1.4647 [0.9361;  2.2919]        5.8\nPulska et al., 1998   1.9436 [1.3441;  2.8107]        6.2\nRoberts et al., 1990  2.3010 [1.9206;  2.7567]        7.0\nSaz et al., 1999      2.1837 [1.5533;  3.0700]        6.3\nSharma et al., 1998   2.0500 [1.0744;  3.9114]        4.7\nTakeida et al., 1997  6.9784 [4.1303; 11.7902]        5.3\nTakeida et al., 1999  5.8124 [3.8816;  8.7035]        6.0\nThomas et al., 1992   1.3303 [0.7780;  2.2745]        5.3\nThomas et al., 1992   1.7722 [1.1073;  2.8363]        5.6\nWeissman et al., 1986 1.2500 [0.6678;  2.3398]        4.8\nZheng et al., 1997    1.9803 [1.4001;  2.8011]        6.3\n\nNumber of studies: k = 18\nNumber of observations: o = 94770\nNumber of events: e = 5439\n\n                         RR           95%-CI    t  p-value\nRandom effects model 2.0217 [1.5786; 2.5892] 6.00 &lt; 0.0001\n\nQuantifying heterogeneity:\n tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462]\n I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 74.49   17 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n\n\nWe gebruiken een andere schattingsmethode om de resultaten nogmaals te controleren (sensitiviteits-analyse), REML ipv MH.\n\nm.bin_update &lt;- update.meta(m.bin, \n                            method.tau = \"REML\")\n\nDe resultaten zijn vrijwel hetzelfde:\n\nexp(m.bin_update$TE.random)\n\n[1] 2.02365\n\n\nHier de schatting voor \\(\\tau^2\\):\n\nm.bin_update$tau2\n\n[1] 0.1647315\n\n\nLaten we daarvoor sm overzetten naar OR:\n\nm.bin_or &lt;- metabin(event.e = event.e, \n                 n.e = n.e,\n                 event.c = event.c,\n                 n.c = n.c,\n                 studlab = author,\n                 data = DepressionMortality,\n                 sm = \"OR\",\n                 method = \"MH\",\n                 MH.exact = TRUE,\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"PM\",\n                 hakn = TRUE,\n                 title = \"Depressie en Mortaliteit\")\nsummary(m.bin_or)\n\nReview:     Depressie en Mortaliteit\n\n                          OR            95%-CI %W(random)\nAaroma et al., 1994   2.2445 [1.4389;  3.5011]        6.3\nBlack et al., 1998    1.8446 [1.3432;  2.5331]        7.0\nBruce et al., 1989    2.7034 [1.0472;  6.9793]        3.7\nBruce et al., 1994    1.2623 [0.7684;  2.0737]        6.0\nEnzell et al., 1984   1.8992 [1.2974;  2.7802]        6.7\nFredman et al., 1989  0.3831 [0.0521;  2.8146]        1.3\nMurphy et al., 1987   2.2733 [1.3248;  3.9011]        5.8\nPenninx et al., 1999  1.6163 [0.8944;  2.9208]        5.5\nPulska et al., 1998   2.9547 [1.4041;  6.2177]        4.7\nRoberts et al., 1990  2.5683 [2.0855;  3.1629]        7.5\nSaz et al., 1999      2.8278 [1.7510;  4.5666]        6.1\nSharma et al., 1998   2.5949 [1.1555;  5.8275]        4.3\nTakeida et al., 1997  7.7354 [4.4252; 13.5219]        5.7\nTakeida et al., 1999  6.7101 [4.3351; 10.3862]        6.4\nThomas et al., 1992   1.3555 [0.7623;  2.4104]        5.6\nThomas et al., 1992   1.8472 [1.1082;  3.0791]        6.0\nWeissman et al., 1986 1.3158 [0.6013;  2.8793]        4.5\nZheng et al., 1997    2.0324 [1.4110;  2.9275]        6.8\n\nNumber of studies: k = 18\nNumber of observations: o = 94770\nNumber of events: e = 5439\n\n                         OR           95%-CI    t  p-value\nRandom effects model 2.2901 [1.7512; 2.9949] 6.52 &lt; 0.0001\n\nQuantifying heterogeneity:\n tau^2 = 0.2032 [0.0744; 0.6314]; tau = 0.4508 [0.2728; 0.7946]\n I^2 = 72.9% [56.7%; 83.0%]; H = 1.92 [1.52; 2.43]\n\nTest of heterogeneity:\n     Q d.f.  p-value\n 62.73   17 &lt; 0.0001\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Paule-Mandel estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)"
  },
  {
    "objectID": "05-between_study_heterogeneity.html",
    "href": "05-between_study_heterogeneity.html",
    "title": "5  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "06-forest_plots.html",
    "href": "06-forest_plots.html",
    "title": "6  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "07-subgroup_analyses.html",
    "href": "07-subgroup_analyses.html",
    "title": "7  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "08-meta_regression.html",
    "href": "08-meta_regression.html",
    "title": "8  Meta-Regressie",
    "section": "",
    "text": "In meta-regressie passen we conventionele regressietechnieken aan op gegevens op studieniveau. Subgroepanalyses kunnen worden gezien als een speciaal geval van meta-regressie met categorische voorspellers en een gemeenschappelijke schatting van \\(\\tau^2\\). Het doel van een meta-regressiemodel is om (delen van) de ware verschillen in effectgrootte in onze data te verklaren (d.w.z. de heterogeniteitsvariantie tussen studies, \\(\\tau^2\\)). Als een model goed bij de gegevens past, moet de afwijking van de ware effecten van de regressielijn kleiner zijn dan hun oorspronkelijke afwijking van het gepoolde effect. Als dit het geval is, zal de onverklaarde of residuele heterogeniteit klein zijn. Dit wordt weergegeven door de R2∗index, die ons vertelt welk percentage van de heterogeniteitsvariatie door ons model wordt verklaard.\nBij meervoudige meta-regressie worden twee of meer voorspellers gebruikt in hetzelfde meta-regressiemodel. Het is ook mogelijk om te testen of de voorspellingen van een variabele veranderen voor verschillende waarden van een andere variabele, door interactietermen te introduceren. Hoewel (meervoudige) meta-regressie erg veelzijdig is, is het niet zonder beperkingen. Meervoudige meta-regressie maakt het erg gemakkelijk om modellen te overfitten, wat betekent dat willekeurige ruis in plaats van echte relaties gemodelleerd worden. Multi-collineariteit van voorspellers kan ook een bedreiging vormen voor de geldigheid van ons model. Er zijn verschillende manieren om ervoor te zorgen dat ons meta-regressiemodel robuust is. We kunnen bijvoorbeeld alleen modellen passen die gebaseerd zijn op een vooraf gedefinieerde theoretische rationale, of permutatietesten gebruiken. Multi-model inferentie kan worden gebruikt als een verkennende aanpak. Deze methode kan ons wijzen op mogelijk belangrijke voorspellers en kan worden gebruikt om hypotheses af te leiden die in toekomstig onderzoek moeten worden getest."
  },
  {
    "objectID": "09-publication_bias.html",
    "href": "09-publication_bias.html",
    "title": "9  Publicatie Bias",
    "section": "",
    "text": "Publicatiebias treedt op wanneer sommige studies systematisch ontbreken in de gepubliceerde literatuur, en dus ook in onze meta-analyse. Strikt genomen is er sprake van publicatiebias als de waarschijnlijkheid dat een studie gepubliceerd wordt afhangt van de resultaten. Er is echter ook een reeks andere vertekeningen in de rapportage. Deze vertekeningen beïnvloeden ook hoe waarschijnlijk het is dat een bevinding in onze meta-analyse terechtkomt. Voorbeelden zijn citatiebias, taalbias of uitkomstbias. Het is ook mogelijk dat gepubliceerd bewijs vertekend is, bijvoorbeeld door twijfelachtige onderzoekspraktijken. Twee veelvoorkomende van dat soort praktijken zijn \\(p\\)-hacking en HARKing, en beide kunnen het risico op overschatting van effecten in een meta-analyse vergroten.\nVeel methoden voor publicatiebias zijn gebaseerd op het idee van kleine-studie-effecten. Deze benaderingen gaan ervan uit dat alleen kleine studies met een verrassend hoge effectgrootte significante resultaten behalen en daarom worden geselecteerd voor publicatie. Dit leidt tot een asymmetrische funnel plot, wat een teken kan zijn van publicatiebias. Maar dat hoeft niet zo te zijn. Er zijn ook verschillende “goedaardige” oorzaken van effecten van kleine studies mogelijk. Een relatief nieuwe methode, p-curve, is gebaseerd op het idee dat we kunnen controleren op bewijskracht door alleen maar te kijken naar het patroon van significante (p&lt;0,05) effecten in onze gegevens. Deze methode kan worden gebruikt om te testen op zowel de aan- als afwezigheid van een echt effect en kan de grootte ervan schatten.\nEr is geen bewijs dat een bepaalde publicatiebias beter veel beter is dan een ander. Maar wat moet je dan kiezen? Om dit probleem aan te pakken, raden we aan om altijd meerdere methoden te gebruiken bij het evalueren van publicatiebias. Hieronder vind je een overzicht van de meest gebruikte methoden met de voor- en nadelen erbij.\n\n\n\nMethoden om de ware effectgrootte te schatten, gecorrigeerd voor publicatiebias: Overzicht van voor- en nadelen.\n\n\n\nVoordelen\nNadelen\n\n\n\n\nDuval & Tweedie Trim-and-Fill\nVery heavily used in practice. Can be interpreted by many researchers.\nOften fails to correct the effect size enough, for example when the true effect is zero. Not robust when the heterogeneity is very large; often outperformed by other methods.\n\n\nPET-PEESE\nBased on a simple and intuitive model. Easy to implement and interpret.\nSometimes massively over- or underestimates the effect. Weak performance for meta-analyses with few studies, low sample sizes, and high heterogeneity.\n\n\nLimit Meta-Analysis\nSimilar approach as PET-PEESE, but explicitly models between-study heterogeneity.\nPerformance is less well studied than the one of other methods. May fail when the number of studies is very low (&lt;10) and heterogeneity very high.\n\n\nP-Curve\nHas been shown to outperform other methods (particularly trim-and-fill) when its assumptions are met.\nWorks under the assumption of no heterogeneity, which is unlikely in practice. Requires a minimum number of significant effect sizes. Less easy to interpret and communicate.\n\n\nSelection Models\nCan potentially model any kind of assumed selection process. The three-parameter selection model has shown good performance in simulation studies.\nOnly valid when the selection model describes the publication bias process adequately. Assume that other small-study effects are not relevant. Can be difficult to interpret and requires background knowledge.\n\n\n\n\n\n\n\nHet is vaak moeilijk, zo niet onmogelijk, om te weten welke aanpak het meest geschikt is voor onze gegevens en of de resultaten betrouwbaar zijn. Zoals we al eerder zeiden, zal de exacte mate waarin selectieve rapportage onze resultaten heeft beïnvloed altijd onbekend zijn. Maar door verschillende publicatiebias technieken toe te passen, kunnen we iets produceren dat lijkt op een reeks geloofwaardige ware effecten.\nSelectiemodellen zijn een zeer veelzijdige methode en kunnen worden gebruikt om verschillende publicatiebiasprocessen te modelleren. Ze geven echter alleen geldige resultaten als het veronderstelde model adequaat is en vereisen vaak een zeer groot aantal onderzoeken. Een zeer eenvoudig selectiemodel, het drieparametermodel, kan ook worden gebruikt voor kleinere datasets. Geen enkele publicatiebiasmethode presteert consistent beter dan alle andere. Het is daarom raadzaam om altijd meerdere technieken toe te passen en de gecorrigeerde effectgrootte voorzichtig te interpreteren. Grondig zoeken naar ongepubliceerd bewijs vermindert het risico van publicatiebias veel beter dan de huidige statistische benaderingen."
  },
  {
    "objectID": "10-multilevel_meta-analysis.html",
    "href": "10-multilevel_meta-analysis.html",
    "title": "10  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "11-seq_meta-analysis.html",
    "href": "11-seq_meta-analysis.html",
    "title": "11  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "12-network_meta-analysis.html",
    "href": "12-network_meta-analysis.html",
    "title": "12  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "13-bayesian_meta-analysis.html",
    "href": "13-bayesian_meta-analysis.html",
    "title": "13  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "14-power_analysis.html",
    "href": "14-power_analysis.html",
    "title": "14  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "15-risk_bias_plots.html",
    "href": "15-risk_bias_plots.html",
    "title": "15  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "16-reporting_reproducibility.html",
    "href": "16-reporting_reproducibility.html",
    "title": "16  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "17-es_calculation_conversion.html",
    "href": "17-es_calculation_conversion.html",
    "title": "17  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "02-discovering_R.html#theory",
    "href": "02-discovering_R.html#theory",
    "title": "2  Discovering R",
    "section": "2.1 Theory",
    "text": "2.1 Theory\nR has become one of the most powerful and frequently used statistical programming languages in the world. Whether you are working in academia or at a company, the things you can do in R will often seem like a superpower to others. But it is a superpower that everyone can learn, provided some time and effort. The book shows how to install R and RStudio (the last one which gives us a user interface which makes it easier to handle our data, packages and output). R is not a computer program with a graphical user interface and pre-defined functionality. It show how it works.\nR is a full programming language to which people all around the world can contribute freely available add-ons, so-called packages. Important packages for working with this book and to do meta-analysis are meta, metafor, dmetar and (for data wrangling) tidyverse. You have to install these on your computer. When installed you have to load them everytime you start your work.\nThe fundamental building blocks of R are functions. Many of these functions can be imported through packages which we can install from the internet. Functions can be used to import, manipulate, transform and save data using R. Examples important for doing meta-analysis in R are given."
  },
  {
    "objectID": "02-discovering_R.html#practice",
    "href": "02-discovering_R.html#practice",
    "title": "2  Discovering R",
    "section": "2.2 Practice",
    "text": "2.2 Practice\nInstall first the packages needed for this book. I had to install an other version of meta to install the package dmetar.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLoad the packages needed for this book.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoading required package: metadat\nLoading required package: numDeriv\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\n\nDownload the example dataset SuicidePrevention.xlx from here and open it.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLet us have a look at the dataset and look at the kind of variables we have.\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nYou can check specfic columns directly\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nAnd look what kind of variable is this:\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLook at the mean of this variable.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nBe sure the variables have the good class, e.g.here numeric. Let us change this for some variables.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwo variables we have to change to factors to analyse them correctly.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn my case the variable age_group is already split in the levels gen and older, see here:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nA logical variable can also be handy, e.g. for the next one:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSometimes it is good to look at specific data from the dataframe. Remember: data.frame[rows, columns]. So look at row 2 becomes\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nIf you want to see information of first column and second row becomes\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nFor selecting parts of the dataframe use c() function. To extract rows 2 and 3 as well as columns 4 and 6 becomes\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRows you select by number, columns you also can select by name,a s in this example.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nYou can also filter a data set based on row values.\nFor example (more examples as given):\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nYou can transform data easy. So, if you want to transform the study of De Vries et al. from 2019 to 2018 you can write it as:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nIf you want to add a new column to your dataframe (e.g mean difference) you can do it as follows:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nOnce we transformed it, we can save it. You can save it as a .rda file\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nor as a .csv file\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\nImportant: Keep your transformation syntax, so you know what you did from original data to the final data."
  },
  {
    "objectID": "03-effect_sizes.html#theory",
    "href": "03-effect_sizes.html#theory",
    "title": "3  Effect Sizes",
    "section": "3.1 Theory",
    "text": "3.1 Theory\nEffect size is defined here as a metric quantifying the relationship between two entities. It captures the direction and magnitude of this relationship. If relationships are expressed as the same effect size, it is possible to compare them.Effect sizes are the building blocks of meta-analyses.\nTo perform a meta-analysis, we need at least an estimate of the effect size and its standard error. They should be comparable, computable, reliable and interpretable. The standard error of an effect size represents how precise the study’s estimate of the effect is. Meta-analysis gives effect sizes with a greater precision a higher weight because they are better estimators of the true effect.\nThere are various effect sizes we can use in meta-analyses. Common ones are “one-variable” relationship measures, such as: - means (summing all individual values deviding by sum of sample size);\n- proportions (number of individuals falling into a specific subgroup deviding by total number of individuals);\n- correlations (expresses teh amount of co-variation between two variables, for example the Pearson Product-Moment Correlation and Point-Biserial Correlation);\n- (standardized) mean differences (difference in means between two independent groups deviding by the pooled standard deviation); - risk ratio (relative risk) as the ratio of two risks; - odds ratio, as the number of cases which fall into a specific subgroup deviding by the number of cases which do not fall into that subgroup. - incidence rate ratios (also called rate ratio), takes into account the person/time-aspects of two groups.\nEffect sizes can also be biased, for example by measurement error and range restriction. There are formulas to correct for some biases, including the small sample bias of standardized mean differences, attenuation due to unreliability, as well as range restriction problems. Other common problems are that studies report the data needed to calculate effect sizes in different formats, as well as the unit-of-analysis problem, which arises when studies contribute more than one effect size."
  },
  {
    "objectID": "03-effect_sizes.html#practice",
    "href": "03-effect_sizes.html#practice",
    "title": "3  Effect Sizes",
    "section": "3.2 Practice",
    "text": "3.2 Practice\nLet us look first at the bewteen-group standardized mean difference (SMD) effect size. It is used when the outcome is continuous and the predictor is categorical. It is the difference in means between two independent groups deviding by the pooled standard deviation. It is also called Cohen’s d.\n\\[SMD_{between} = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p}\\]\nwhere \\(\\bar{X}_1\\) and \\(\\bar{X}_2\\) are the means of the two groups and \\(s_p\\) is the pooled standard deviation. SMD’s are often interpreted as small (0.2), medium (0.5) and large (0.8) effects.\nThere are several functions in R which allow us to calculate SMDbetween/Cohen’s d in one step. Here, we use the esc_mean_sd function, which is part of the esc-package. We have not used this package before, so it is necessary to install it first.\n\n# install.packages(\"esc\")\nlibrary(esc)\n\n# Define the data we need to calculate SMD/d\n# This is just some example data that we made up\ngrp1m &lt;- 50   # mean of group 1\ngrp2m &lt;- 60   # mean of group 2\ngrp1sd &lt;- 10  # sd of group 1\ngrp2sd &lt;- 10  # sd of group 2\ngrp1n &lt;- 100  # n of group1\ngrp2n &lt;- 100  # n of group2\n\n# Calculate effect size\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and sd to effect size d\n    Effect Size:  -1.0000\n Standard Error:   0.1500\n       Variance:   0.0225\n       Lower CI:  -1.2940\n       Upper CI:  -0.7060\n         Weight:  44.4444\n\n\nTo conduct a meta-analysis of standardized mean differences, our data set should at least contain the following columns:\n\nn.e. The number of observations in the intervention/experimental group.\nmean.e. The mean of the intervention/experimental group.\nsd.e. The standard deviation in the intervention/experimental group.\nn.c. The number of observations in the control group.\nmean.c. The mean of the control group.\nsd.c. The standard deviation in the control group.\n\nFor binary outcomes odds ratios can be used. The esc_2x2 function in the esc package provides an easy way to calculate the (log) odds ratio in R.\n\nlibrary(esc)\n\n# Define data\ngrp1yes &lt;- 45  # events in the treatment group\ngrp1no &lt;- 98   # non-events in the treatment group\ngrp2yes &lt;- 67  # events in the control group\ngrp2no &lt;- 76   # non-events in the control group\n\n# Calculate OR by setting es.type to \"or\"\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n    Effect Size:   0.5209\n Standard Error:   0.2460\n       Variance:   0.0605\n       Lower CI:   0.3216\n       Upper CI:   0.8435\n         Weight:  16.5263\n\n\nTo conduct a meta-analysis of odds ratios in R, the following columns should be included in our data set:\n\nevent.e. The number of events in the treatment or experimental group.\n\nn.e. The sample size of the treatment or experimental group.\n\nevent.c. The number of events in the control group.\n\nn.c. The sample size of the control group.\n\nFor a practice sample for correction we look at small sample correction. We can easily convert unstandardized SMDs/Cohen’s dto Hedges’ g using the hedges_g function in the esc-package.\n\n# Load esc package\nlibrary(esc)\n\n# Define uncorrected SMD and sample size n\nSMD &lt;- 0.5\nn &lt;- 30\n\n# Convert to Hedges g\ng &lt;- hedges_g(SMD, n)\ng\n\n[1] 0.4864865"
  },
  {
    "objectID": "02-discovering_R.html#theorie",
    "href": "02-discovering_R.html#theorie",
    "title": "2  R ontdekken",
    "section": "2.1 Theorie",
    "text": "2.1 Theorie\nR is uitgegroeid tot een van de krachtigste en meest gebruikte statistische programmeertalen ter wereld. Of je nu in de academische wereld werkt of in een bedrijf, de dingen die je in R kunt doen lijken vaak een superkracht voor anderen. Maar het is een superkracht die iedereen kan leren, mits je er wat tijd en moeite in stot.\nHet boek laat zien hoe je R en RStudio installeert (de laatste geeft ons een gebruikersinterface die het makkelijker maakt om met onze gegevens, pakketten en uitvoer om te gaan). R is geen computerprogramma met een grafische gebruikersinterface en voorgedefinieerde functionaliteit. RStudio laat jou makkelijker met R werken. R is de moter en RStduio is meer het dashboard. Het boek laat zien hoe het met elkaar werkt.\nR is een volledige programmeertaal waaraan mensen over de hele wereld met vrij beschikbare uitbreidingen, zogenaamde specifieke pakketten, kunnen bijdragen. Belangrijke specifieke pakketten voor het werken met dit boek en het doen van meta-analyse met R zijn meta (zie bv hier), metafor(zie bv hier), dmetar (zie hier) en (voor data bewerking) tidyverse (zie hier.\nNadat je R en RStudio hebt geïnstalleerd op jouw computer, moet deze pakketten installeren op je computer. De fundamentele bouwstenen van R zijn functies, waarmee in dit hoofdstuk wordt gewerkt en waarmee je een goed idee krijgt hoe een en ander voor het uitvoeren van meta-analyses werkt. Veel van de functies kunnen worden geïmporteerd en uitgevoerd via pakketten die met internet zijn te installeren. Functies kunnen worden gebruikt om gegevens te importeren, te manipuleren, te transformeren en op te slaan met behulp van R. Er worden voorbeelden gegeven van basisfuncties die belangrijk zijn voor het uitvoeren van meta-analyses in R en in de hoofdstukken hierna worden uitgevoerd."
  },
  {
    "objectID": "02-discovering_R.html#practijk",
    "href": "02-discovering_R.html#practijk",
    "title": "2  Discovering R",
    "section": "2.2 Practijk",
    "text": "2.2 Practijk\nInstalleer eerst de pakketten die nodig zijn voor dit boek. Ik moest zelf een vorige versie van meta installeren om het pakket dmetar te installeren. Als je dit niet eerder hebt gedaan met je de hekjes (#) weghalen en de code uitvoeren. Dat installeren hoef je maar één keer te doen.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLaad de pakketten die nodig zijn om de voorbeelden in dit boek uit te voeren.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nHaal ook de datasetSuicidePrevention.xlx die je hier vandaan kunt halen en open die set.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLaten we naar die dataset kijken en zien welke variabelen er zijn. Er zijn tien kolommen (variabelen) en negen rijgen (individuele studies)\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nJe kunt de inhoud van een bepaalde kolommen alleen bekijken, bv deze:\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nEn je kunt ook zien wat voor een soort variabele het is.\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLaten we het gemiddelde van deze variabele vaststellen.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nZorg ervoor dat de variabelen de goede klasse hebben, bijvoorbeeld numeriek. Laten we dit veranderen voor enkele variabelen.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwee variabelen moeten we veranderen in factoren om de analyse later correct te kunnen uitvoeren.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn dit geval is de variabele age_group opgesplitst in de niveaus gen en older, zie hier:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nEen logische variabele kan ook handig zijn, bijvoorbeeld voor de volgende variabele:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\nDeze zetten we om in een logische variabele.\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSoms is het goed om naar specifieke gegevens uit het dataframe te kijken. Onthoud: data.frame[rijen, kolommen]. Dus kijken naar rij 2 wordt:\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nAls je informatie van de eerste kolom én de tweede rij wilt zien, schrijf je:\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nGebruik de functie c() om delen van het dataframe te selecteren. Om rijen 2 en 3 en kolommen 4 en 6 te extraheren wordt\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRijen selecteer je op nummer, kolommen kun je ook op naam selecteren, zoals in dit voorbeeld.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nJe kunt voor een gegevensverzameling ook de functie filter gebruiken, die werkt op basis van rijwaarden, bijvoorbeeld de rijwaarden van n.e. zijn kleiner of gelijk aan 50. Dan schrijf je:\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nJe kunt gegevens zelf gemakkelijk transformeren. Dus als je de studie van De Vries et al. wilt transformeren van 2019 naar 2018, kun je het schrijven als:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nAls je een nieuwe kolom wilt toevoegen aan je dataframe (bijvoorbeeld het gemiddelde verschil), kun je dat als volgt doen:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nZodra alles is getransformeerd, kunnen we het bewerkte bestand opslaan. Je kunt het opslaan als een .rda-bestand, zo dan:\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nof opslaan als een .csv-bestand, zo dan:\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\n\nBewaar je transformatie syntax, zodat je weet wat je hebt gedaan van de originele gegevens naar de uiteindelijke gegevens."
  },
  {
    "objectID": "02-discovering_R.html#praktijk",
    "href": "02-discovering_R.html#praktijk",
    "title": "2  R ontdekken",
    "section": "2.2 Praktijk",
    "text": "2.2 Praktijk\nInstalleer eerst de pakketten die nodig zijn voor dit boek. Ik moest zelf een vorige versie van meta installeren om het pakket dmetar te installeren. Als je dit niet eerder hebt gedaan met je de hekjes (#) weghalen en de code uitvoeren. Dat installeren hoef je maar één keer te doen.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLaad de pakketten die nodig zijn om de voorbeelden in dit boek uit te voeren.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nHaal ook de datasetSuicidePrevention.xlx die je hier vandaan kunt halen en open die set.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLaten we naar die dataset kijken en zien welke variabelen er zijn. Er zijn tien kolommen (variabelen) en negen rijgen (individuele studies)\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nJe kunt de inhoud van een bepaalde kolommen alleen bekijken, bv deze:\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nEn je kunt ook zien wat voor een soort variabele het is.\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLaten we het gemiddelde van deze variabele vaststellen.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nZorg ervoor dat de variabelen de goede klasse hebben, bijvoorbeeld numeriek. Laten we dit veranderen voor enkele variabelen.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwee variabelen moeten we veranderen in factoren om de analyse later correct te kunnen uitvoeren.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn dit geval is de variabele age_group opgesplitst in de niveaus gen en older, zie hier:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nEen logische variabele kan ook handig zijn, bijvoorbeeld voor de volgende variabele:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\nDeze zetten we om in een logische variabele.\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSoms is het goed om naar specifieke gegevens uit het dataframe te kijken. Onthoud: data.frame[rijen, kolommen]. Dus kijken naar rij 2 wordt:\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nAls je informatie van de eerste kolom én de tweede rij wilt zien, schrijf je:\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nGebruik de functie c() om delen van het dataframe te selecteren. Om rijen 2 en 3 en kolommen 4 en 6 te extraheren wordt\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRijen selecteer je op nummer, kolommen kun je ook op naam selecteren, zoals in dit voorbeeld.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nJe kunt voor een gegevensverzameling ook de functie filter gebruiken, die werkt op basis van rijwaarden, bijvoorbeeld de rijwaarden van n.e. zijn kleiner of gelijk aan 50. Dan schrijf je:\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nJe kunt gegevens zelf gemakkelijk transformeren. Dus als je de studie van De Vries et al. wilt transformeren van 2019 naar 2018, kun je het schrijven als:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nAls je een nieuwe kolom wilt toevoegen aan je dataframe (bijvoorbeeld het gemiddelde verschil), kun je dat als volgt doen:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nZodra alles is getransformeerd, kunnen we het bewerkte bestand opslaan. Je kunt het opslaan als een .rda-bestand, zo dan:\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nof opslaan als een .csv-bestand, zo dan:\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\n\n\n\n\n\n\nImportant\n\n\n\nBewaar je transformatie syntax, zodat je weet wat je hebt gedaan van de originele gegevens naar de uiteindelijke gegevens."
  },
  {
    "objectID": "03-effect_sizes.html#theorie",
    "href": "03-effect_sizes.html#theorie",
    "title": "3  Effect Sizes",
    "section": "3.1 Theorie",
    "text": "3.1 Theorie\nEffect size wordt hier gedefinieerd als een metriek die de relatie tussen twee entiteiten kwantificeert. Het geeft de richting en sterkte van deze relatie weer. Als relaties worden uitgedrukt in een vergelijkbare effect size, is het mogelijk om ze te vergelijken. Effect sizes zijn de bouwstenen van meta-analyses.Om een meta-analyse uit te voeren, is op zijn minst een schatting nodig van de effect size en de standaard-fout ervan. Deze moeten vergelijkbaar, berekenbaar, betrouwbaar en interpreteerbaar zijn. De standaard-fout van een effect size geeft aan hoe nauwkeurig de schatting van het effect van de studie is. Meta-analyse geeft effect-sizes met een grotere precisie een hoger gewicht omdat ze betere schatters zijn van het ware effect.\nEr zijn verschillende effectmaten die we kunnen gebruiken in meta-analyses. Gebruikelijke zijn “één-variabele” relatiematen, zoals:\n- gemiddelden (som van alle individuele waarden, gedeeld door de som van de steekproefgrootte);\n- proporties (aantal individuen dat in een specifieke subgroep valt, gedeeld door het totale aantal individuen);\n- correlaties (drukt de mate van co-variatie tussen twee variabelen uit, bijvoorbeeld de Pearson Product-Moment Correlatie en Point-Biserial Correlatie);\n- risicoverhouding (relatief risico) als de verhouding tussen twee risico’s;\n- odds ratio, als het aantal gevallen dat in een bepaalde subgroep valt, gedeeld door het aantal gevallen dat niet in die subgroep valt;\n- incidentieratio’s (ook wel rate ratio genoemd), houdt rekening met de persoon/tijd-aspecten van twee groepen.\nEffectgroottes kunnen ook vertekend zijn, bijvoorbeeld door meetfouten en bereikbeperking. Er bestaan formules om te corrigeren voor sommige vertekeningen, waaronder de kleine steekproefvertekening van gestandaardiseerde gemiddelde verschillen, verzwakking door onbetrouwbaarheid en problemen met bereikbeperking. Andere veel voorkomende problemen zijn dat studies de gegevens die nodig zijn om effectgroottes te berekenen in verschillende formaten rapporteren, evenals het probleem van de analyse-eenheid, dat optreedt wanneer studies meer dan één effect size bijdragen."
  },
  {
    "objectID": "03-effect_sizes.html#praktijk",
    "href": "03-effect_sizes.html#praktijk",
    "title": "3  Effect Sizes",
    "section": "3.2 Praktijk",
    "text": "3.2 Praktijk\nLaten we eerst kijken naar de gestandaardiseerde size van het verschil tussen groepen (SMD). Deze wordt gebruikt als de uitkomst continu is en de voorspeller categorisch. Het is het verschil in gemiddelden tussen twee onafhankelijke groepen gedeeld door de gepoolde standaardafwijking. Het wordt ook Cohen’s \\(d\\) genoemd.\n\\[SMD_{between} = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p}\\]\nwaarbij \\(\\bar{X}_1\\) en \\(\\bar{X}_2\\) de gemiddelden van de twee groepen zijn en \\(s_p\\) de gepoolde standaardafwijking. SMD’s worden vaak geïnterpreteerd als kleine (0,2), middelgrote (0,5) en grote (0,8) effecten. Er zijn verschillende functies in R waarmee we SMDbetween/Cohen’s d in één stap kunnen berekenen. Hier gebruiken we de functie esc_mean_sd, die deel uitmaakt van het esc-pakket. We hebben dit pakket nog niet eerder gebruikt, dus het is noodzakelijk om het eerst te installeren.\n\n# install.packages(\"esc\")\nlibrary(esc)\n\n# Defineeer data die nodig zijn om SMD/d te berekenen\n# Dit is een eenvoudig voorbeeld om een dataset te maken\ngrp1m &lt;- 50   # gemiddelde van groep 1\ngrp2m &lt;- 60   # gemiddelde van groep 2\ngrp1sd &lt;- 10  # sd van groep 1\ngrp2sd &lt;- 10  # sd van groep 2\ngrp1n &lt;- 100  # n van groep 1 \ngrp2n &lt;- 100  # n van groep 2\n\n# CalculEER effect size\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and sd to effect size d\n    Effect Size:  -1.0000\n Standard Error:   0.1500\n       Variance:   0.0225\n       Lower CI:  -1.2940\n       Upper CI:  -0.7060\n         Weight:  44.4444\n\n\nOm een meta-analyse van gestandaardiseerde gemiddelde verschillen uit te voeren, moet onze dataset ten minste de volgende kolommen bevatten:\n\nn.e. Het aantal observaties in de interventie/experimentele groep.\n\nmean.e. Het gemiddelde van de interventie/experimentele groep.\n\nsd.e. De standaardafwijking in de interventie/experimentele groep.\n\nn.c. Het aantal observaties in de controlegroep.\n\nmean.c. Het gemiddelde van de controlegroep.\n\nsd.c. De standaardafwijking in de controlegroep.\n\nVoor binaire uitkomsten kunnen kansverhoudingen worden gebruikt. De functie esc_2x2 in het pakket esc biedt een eenvoudige manier om de (log)odds ratio in R te berekenen.\n\nlibrary(esc)\n\n# Defineeer data die nodig zijn om de odds ratio te berekenen\ngrp1yes &lt;- 45  # gebeurtenissen in de behandelingsgroep\ngrp1no &lt;- 98   # niet-gebeurtenissen in de behandelingsgroep\ngrp2yes &lt;- 67  # gebeurtenissen in de controlegroep\ngrp2no &lt;- 76   # niet-gebeurtenissen in de controlegroep\n\n# Calculeer OR door es.type op \"or\" te zetten\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n    Effect Size:   0.5209\n Standard Error:   0.2460\n       Variance:   0.0605\n       Lower CI:   0.3216\n       Upper CI:   0.8435\n         Weight:  16.5263\n\n\nOm een meta-analyse van odds ratio’s uit te voeren in R, moeten de volgende kolommen worden opgenomen in onze dataset:\n\nevent.e. Het aantal geberutenissen in de experimentele groep.\nn.e. De sample size van de experimentele groep.\n\nevent.c. Het aantal gebeurtenissen in de controle groep.\n\nn.c. De sample size van de controle groep.\n\nVoor een voorbeeld voor correctie kijken we naar kleine steekproefcorrectie. We kunnen niet-gestandaardiseerde SMD’s/Cohen’s d eenvoudig omzetten naar Hedges’ g met behulp van de hedges_g functie in het esc pakket.\n\n# Laad esc pakket\nlibrary(esc)\n\n# Defineer niet aangepast SMD en sample size n\nSMD &lt;- 0.5\nn &lt;- 30\n\n# Zet om naar Hedges g\ng &lt;- hedges_g(SMD, n)\ng\n\n[1] 0.4864865"
  },
  {
    "objectID": "05-between_study_heterogeneity.html#theorie",
    "href": "05-between_study_heterogeneity.html#theorie",
    "title": "5  Heterogeniteit tussen studies",
    "section": "5.1 Theorie",
    "text": "5.1 Theorie\nIn meta-analyses moeten we niet alleen letten op de gepoolde (samen gebrachte) effectgrootte, maar ook op de heterogeniteit van de gegevens waarop dit gemiddelde effect is gebaseerd. Het totale effect legt niet vast dat de werkelijke effecten in sommige onderzoeken aanzienlijk kunnen verschillen van de puntschatting (bijv. subgroepen kunnen hele verschillende uitkomsten laten zien). Elke goede meta-analyse moet niet alleen een globaal overall-effect rapporteren, maar ook aangeven hoe betrouwbaar deze schatting is. Een essentieel onderdeel hiervan is het kwantificeren en analyseren van de heterogeniteit tussen studies \\(\\zeta_k\\) (anders dan de steekproeffout \\(\\epsilon_k\\)).\nCochran’s \\(Q\\) wordt vaak gebruikt om de variabiliteit in de meta-analyse gegevens te kwantificeren. Omdat we weten dat \\(Q\\) een verdeling van \\(\\chi^2\\) volgt, stelt deze maat ons in staat om te detecteren of er meer variatie aanwezig is dan verwacht kan worden op basis van alleen steekproeffouten. Deze overmatige variabiliteit bovenop de steekproeffout vertegenwoordigt echte verschillen in de effectgroottes van studies.\nEen statistische test van \\(Q\\) hangt echter sterk af van het type gegevens dat we hebben. We moeten niet alleen op \\(Q\\) vertrouwen om de mate van heterogeniteit te beoordelen. Er zijn andere maten, zoals \\(I^2\\), \\(H^2\\), \\(tau\\) of voorspellingsintervallen, die aanvullend gebruikt kunnen worden om iets over de tussen-studie-heterogeniteit te zeggen.\nHet gemiddelde effect in een meta-analyse kan vertekend zijn als er uitschieters in onze gegevens zitten. Uitschieters hebben niet altijd een grote invloed op de resultaten van een meta-analyse. Maar als ze dat wel doen, spreken we van invloedrijke gevallen. Er zijn verschillende methoden om uitschieters en invloedrijke gevallen te identificeren. Als dergelijke studies die eruit schieten worden ontdekt, is het raadzaam om de resultaten van de meta-analyse opnieuw te berekenen zonder deze studies om te zien of dit de interpretatie van onze resultaten verandert."
  },
  {
    "objectID": "05-between_study_heterogeneity.html#practice",
    "href": "05-between_study_heterogeneity.html#practice",
    "title": "5  Between-Study-Herterogeneity",
    "section": "5.2 Practice",
    "text": "5.2 Practice\nOok hier de onderstaande pakketten laden, het databestand ThirdWave openen en dit databestand goed bekijken.\n\nlibrary(tidyverse) # needed for 'glimpse'\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\nEr zitten acht variabelen (kolommen) in (Author, Year, TE, seTE, RiskOfBias, TypeControlGroup, InterventionDuration, InterventionType, and ModeOfDelivery) en achttien studies (rijen) in. De uitkomstmaat is TE (Treatment Effect) en de standaardfout van de uitkomstmaat is seTE (Standard Error of the Treatment Effect). De variabele Author bevat de namen van de auteurs van de studies. De uitkomstmaat is een Standardized Mean Difference (SMD), er wordt een random-effects model gebruikt met de methode REML.\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\nWe gaan het voorspellen.\n\nm.gen &lt;- update.meta(m.gen, prediction = TRUE)\n\nWe kunnen de resultaten van de meta-analyse bekijken met de summary functie.\n\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0572; 1.2115]              \n\nQuantifying heterogeneity:\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 16)\n\n\nDit is wat er gerapporteerd kan worden: &gt; “De heterogeniteitsvariantie tussen studies werd geschat op \\(\\tau^2\\) = 0,08 (95%CI: 0,03-0,35), met een \\(I^2\\)-waarde van 63% (95%CI: 38-78%). Het voorspellingsinterval varieerde van \\(g\\) = -0,06 tot 1,21, wat aangeeft dat negatieve interventie-effecten niet kunnen worden uitgesloten voor toekomstige studies.”\nOm uitschieters te vinden hebben we de functie find.outliers gebruikt, die een object nodig heeft dat is gemaakt door de functie metagen.\n\nfind.outliers(m.gen)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"DanitzOrsillo\", \"Shapiro et al.\" \n \nResults with outliers removed \n----------------------------- \nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 16\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.4528 [0.3257; 0.5800] 7.59 &lt; 0.0001\nPrediction interval              [0.1687; 0.7369]              \n\nQuantifying heterogeneity:\n tau^2 = 0.0139 [0.0000; 0.1032]; tau = 0.1180 [0.0000; 0.3213]\n I^2 = 24.8% [0.0%; 58.7%]; H = 1.15 [1.00; 1.56]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 19.95   15  0.1739\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 15)\n- Prediction interval based on t-distribution (df = 14)\n\n\nWe zien dat de find.outliers functie twee uitschieters detecteerde, “DanitzOrsillo” en “Shapiro et al.”. Het {dmetar} pakket bevat ook een functie genaamd InfluenceAnalysis, waarmee we deze verschillende invloedsdiagnoses kunnen berekenen met behulp van één functie. De functie kan worden gebruikt voor elk type meta-analyseobject dat is gemaakt door {meta} functies. We slaan de resultaten van de functie op in een object genaamd m.gen.inf.\n\nm.gen.inf &lt;- InfluenceAnalysis(m.gen, random = TRUE)\n\n[===========================================================================] DONE \n\n\nDit creëert een baujat plot, die een grafische weergave geeft van de invloed van elke studie op de heterogeniteit van de meta-analyse.\n\nplot(m.gen.inf, \"baujat\")\n\nWarning: ggrepel: 12 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\nDe volgende plot bevat verschillende invloedsdiagnoses voor elk van onze onderzoeken. Deze kunnen worden uitgezet met deze code:\n\nplot(m.gen.inf, \"influence\")\n\n\n\n\nHet {dmetar} pakket bevat, tenslotte, ook een functie genaamd InfluenceAnalysis, waarmee we deze resultaten kunnen berekenen met behulp van de ‘leave-one-out’-methode. De eerste is gesorteerd op effectgrootte, de tweede op heterogeniteit.\n\nplot(m.gen.inf, \"es\")\n\n\n\nplot(m.gen.inf, \"i2\")"
  },
  {
    "objectID": "10-multilevel_meta-analysis.html#theorie",
    "href": "10-multilevel_meta-analysis.html#theorie",
    "title": "10  “Multilevel” Meta-Analysis",
    "section": "10.1 Theorie",
    "text": "10.1 Theorie\nAls mensen het over multilevel meta-analyse hebben, denken ze aan meta-analyse modellen op drie niveaus. In Doing meta-analysis with R beschrijven Harrer et al. waarom meta-analyse van nature al een multilevel structuur van de data heeft en laten ze zien hoe zo’n conventionele meta-analyse kan worden uitbreid naar een model op drie niveaus. Aan de hand van een praktijkvoorbeeld laten ze het zien hoe het werkt in R.\nZe gaan eerst terug naar de random-effects model formule die ons bekend is: Deze formule beschrijft dus eigenlijk al een multilevelstructuur van meta-analysegegevens. Om dit duidelijker te maken, wordt de vergelijking opgesplitst in twee formules, waarbij elke formule correspondeert met een van de twee niveaus. Als we dit doen, krijgen we het volgende resultaat:\nNiveau 1 (participanten) model:\n\\[\\hat\\theta_k = \\theta_k + \\epsilon_k\\]\nNiveau 2 (studies) model:\n\\[\\theta_k = \\mu + \\zeta_k\\]\nDit oude-vertrouwde meta-analysemodel heeft de multilevel-eigenschap “ingebouwd”. Het heeft namelijk deze eigenschap omdat we aannemen dat deelnemers geclusterd zijn binnen studies in onze data. Het is nu mogelijk om deze twee-niveausstructuur verder uit te breiden om bepaalde mechanismen, die onze data hebben gegenereerd, beter vast te leggen. Dit is waar drie-niveaumodellen om de hoek komen kijken (Cheung 2014; Assink, Wibbelink, et al. 2016).\nModellen met drie niveaus kunnen worden gebruikt voor afhankelijke effectgroottes. Wanneer een bepaalde studie bijvoorbeeld meer dan één effect sizes omvat, kunnen we er meestal niet vanuit gaan dat deze verschillende resultaten onafhankelijk zijn. Een drie niveaumodel ondervangt dit probleem door aan te nemen dat effect sizes geclusterd zijn binnen grotere clusters (in dit geval bijvoorbeeld studies).\nDie model met drie niveau’s ziet er als volgt uit:\n\n\n\nDrie niveaustructuur\n\n\nHet is mogelijk om de formule van dit model met drie lagen op te schrijven met dezelfde formules die we hierboven gebruikten. Het grootste verschil is dat we nu drie formules moeten definiëren in plaats van twee:\nLevel 1 model:(participanten)\n\\[\\hat\\theta_{ij} = \\theta_{ij} + \\epsilon_{ij}\\]\nLevel 2 model:(binnen studies)\n\\[\\theta_{ij} = \\kappa_{j} + \\zeta_{(2)ij}\\]\nLevel 3 model:(tussen studies)\n\\[\\kappa_{j} = \\mu + \\zeta_{(3)j}\\]\nWaarbij \\(\\hat\\theta_{ij}\\) een schatting is van de ware effectgrootte \\(\\theta_{ij}\\). De term \\(ij\\) kan worden gelezen als “een effect size” \\(i\\) geclusterd in cluster \\(j\\)“. De parameter \\(\\kappa_{j}\\) is de gemiddelde effect size in cluster \\(j\\), en \\(\\mu\\) het totale gemiddelde populatie-effect. Net als voorheen kunnen we deze formules samenvoegen en zo de formule reduceren tot één regel:\n\\[\\hat\\theta_{ij} = \\mu + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\\]\nIn tegenstelling tot de conventionele meta-analyse (random-effects models) schatten modellen met drie niveau’s twee heterogeniteitsvarianties: de random-effectvariantie binnen clusters en de heterogeniteitsvariantie tussen clusters (de clusters zijn in dit geval studies). Het is ook mogelijk om categorische of continue voorspellers te testen met een model met drie niveaus. Dit resulteert in een mixed-effects model met drie niveaus."
  },
  {
    "objectID": "10-multilevel_meta-analysis.html#praktijk",
    "href": "10-multilevel_meta-analysis.html#praktijk",
    "title": "10  “Multilevel” Meta-Analysis",
    "section": "10.2 Praktijk",
    "text": "10.2 Praktijk\n\n10.2.1 Voorbereiding\nHet {metafor} pakket is heel geschikt om meta-analyse op drie niveau’s uit te voeren. Het gebruikt ‘(restricted) maximum likelihood’ (REML-) procedures om dat te doen.\nWe moeten eerst de biblitheek hiervan openen.\n\n# Wees er zeker van dat het pakket is geïnstalleerd\nlibrary(metafor)\n\nVoor hier gebruiken we de Chernobyl data set. xxx Die dataset is deel van het dmetar pakket waar meer datasets voor meta-analyse in zitten. Laten we ook dat pakket, het pakket en de data set laden. Laten we meteen ook tidyverse laden, omdat we dat later nodig hebben.\n\n# Wees er zeker van dat het pakket is geïnstalleerd\nlibrary(dmetar)\nlibrary(tidyverse)\ndata(Chernobyl)\n\nLaten we eens zien hoe die dataset eruit ziet.\n\nhead(Chernobyl)\n\n                      author    cor   n         z       se.z       var.z\n1 Aghajanyan & Suskov (2009) 0.2061  91 0.2090949 0.10660036 0.011363636\n2 Aghajanyan & Suskov (2009) 0.2687  91 0.2754621 0.10660036 0.011363636\n3 Aghajanyan & Suskov (2009) 0.2049  92 0.2078420 0.10599979 0.011235955\n4 Aghajanyan & Suskov (2009) 0.2672  92 0.2738461 0.10599979 0.011235955\n5     Alexanin et al. (2010) 0.9317 559 1.6711230 0.04240945 0.001798561\n6     Alexanin et al. (2010) 0.4429 559 0.4758327 0.04240945 0.001798561\n  radiation es.id\n1       low  id_1\n2       low  id_2\n3       low  id_3\n4       low  id_4\n5       low  id_5\n6       low  id_6\n\nglimpse(Chernobyl)\n\nRows: 33\nColumns: 8\n$ author    &lt;chr&gt; \"Aghajanyan & Suskov (2009)\", \"Aghajanyan & Suskov (2009)\", …\n$ cor       &lt;dbl&gt; 0.2061, 0.2687, 0.2049, 0.2672, 0.9317, 0.4429, 0.8996, 0.95…\n$ n         &lt;dbl&gt; 91, 91, 92, 92, 559, 559, 559, 559, 559, 559, 560, 15, 79, 9…\n$ z         &lt;dbl&gt; 0.20909489, 0.27546213, 0.20784198, 0.27384610, 1.67112298, …\n$ se.z      &lt;dbl&gt; 0.10660036, 0.10660036, 0.10599979, 0.10599979, 0.04240945, …\n$ var.z     &lt;dbl&gt; 0.011363636, 0.011363636, 0.011235955, 0.011235955, 0.001798…\n$ radiation &lt;chr&gt; \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low…\n$ es.id     &lt;chr&gt; \"id_1\", \"id_2\", \"id_3\", \"id_4\", \"id_5\", \"id_6\", \"id_7\", \"id_…\n\n\nDe data set omvat acht kolommen (variabelen) en 33 rijen (studies). De eerste, author, geeft de naam van het onderzoek weer. De kolom cor toont de (niet-getransformeerde) correlatie tussen stralingsblootstelling en mutatiepercentages, terwijl n staat voor de steekproefgrootte. De kolommen z, se.z, en var.z zijn de Fisher-\\(z\\) getransformeerde correlaties, evenals hun standaardfout en variantie. De kolom radiation dient als moderator, die effectgroottes verdeelt in twee subgroepen, één met een lage en één met hoge totale stralingsblootstelling. De kolom es.id bevat eenvoudigweg een unieke ID voor elke effectgrootte (d.w.z. elke rij in ons dataframe).\nEen eigenaardigheid aan deze dataset is dat er herhaalde (geclusterde) vermeldingen in de kolom author staan. Dit komt doordat de meeste studies in deze meta-analyse meer dan één waargenomen effectgrootte hebben bijgedragen. Als we naar deze structuur kijken, is het duidelijk dat effectgroottes in onze dataset niet onafhankelijk zijn. Ze volgen een geclusterde structuur, waarbij verschillende effectgroottes geclusterd zijn in één studie. Het zou dus een goed idee kunnen zijn om een meta-analyse op drie niveaus uit te voeren om deze afhankelijkheden in onze gegevens adequaat te modelleren.\n\n\n10.2.2 Het fitten van een drie niveau ma-model\nEen meta-analysemodel met drie niveaus kan worden uitgevoerd met de functie rma.mv in {metafor}. Hier is een lijst van de belangrijkste argumenten voor deze functie en hoe ze gespecificeerd moeten worden:\n\n\nyi. De naam van de kolom in onze dataset die de berekende effectgroottes bevat. In ons voorbeeld is dit z, omdat Fisher-\\(z\\) getransformeerde correlaties betere wiskundige eigenschappen hebben dan “niet-getransformeerde” correlaties.\n\nV. De naam van de kolom in onze gegevensverzameling is die de variantie van de berekende effectgroottes bevat. In ons geval is dit var.z. Het is ook mogelijk om de gekwadrateerde standaardfout van de effectgrootte te gebruiken, aangezien \\(SE^2_k=vk\\)\n\ns.lab. De naam van de kolom in onze dataset die de studielabels bevat.\n\ndata. De naam van de data set.\n\ntest. De test die we willen toepassen op onze regressiecoëfficiënten. We kunnen kiezen uit \"z\" (standaard) en \"t\" (aanbevolen; gebruikt een test vergelijkbaar met de Knapp-Hartung methode).\n\nmethode. De methode die wordt gebruikt om de modelparameters te schatten. Zowel \"REML\" (aanbevolen; restricted maximum-likelihood) als \"ML\" (maximum likelihood) zijn mogelijk. Hou er rekening mee dat andere soorten heterogeniteitsschattingen tussen studies (bijv. Paule-Mandel) hier niet van toepassing zijn.\nrandom. De naam van de kolom die hier het belangrijkst is. de algemene structuur van de formule ziet er als volgt uit: ~ 1 | cluster/effecten_binnen_cluster. Hier gaan we uit van een structuur met drie niveaus: individuen (niveau 1), individuele effectgroottes (niveau 2) en studies (niveau 3), dus krijgen we de formule ~ 1 | author/es.id.\n\n\nfull.model &lt;- rma.mv(yi = z, \n                     V = var.z, \n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id, \n                     test = \"t\", \n                     method = \"REML\")\n\nDe resultaten van dit multilevel model kun je vervolgens krijgen door summary functie in te tikken:\n\nsummary(full.model)\n\n\nMultivariate Meta-Analysis Model (k = 33; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-21.1229   42.2458   48.2458   52.6430   49.1029   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed        factor \nsigma^2.1  0.1788  0.4229     14     no        author \nsigma^2.2  0.1194  0.3455     33     no  author/es.id \n\nTest for Heterogeneity:\nQ(df = 32) = 4195.8268, p-val &lt; .0001\n\nModel Results:\n\nestimate      se    tval  df    pval   ci.lb   ci.ub      \n  0.5231  0.1341  3.9008  32  0.0005  0.2500  0.7963  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nKijk naar deVariance Components:\n- sigma^2.1 toont de variantie op niveau 3 (variantie tussen clusters). Dit komt overeen met de heterogeniteitsvariantie tussen studies \\(tau^2\\) van een conventionele meta-analyse (aangezien de clusters author (14 stuks in totaal) in ons model studies vertegenwoordigen). Dit is gelijk aan 33 effectgroottes (author/es.id) en de heterogeniteitsvariantie binnen studies.\n- Onder Modelresultaten zien we de schatting van ons gepoolde effect (\\(z=\\) 0.52 (95%CI: 0.25-0.80)). Om de interpretatie te vergemakkelijken, is het raadzaam om het effect terug te transformeren naar een normale correlatie. Dit kan worden gedaan met de functie convert_z2r in het pakket {esc}:\n\nlibrary(esc)\nconvert_z2r(0.52)\n\n[1] 0.4777\n\n\nWe zien dat dit leidt tot een correlatie van ongeveer $\\(0,48. Dit kan als groot worden beschouwd. Er lijkt een substantieel verband te zijn tussen mutatiepercentages en blootstelling aan straling van Tsjernobyl. De `Test voor Heterogeniteit` in de uitvoer wijst op echte effectgrootteverschillen in onze gegevens (\\)p$&lt;0,001). Dit resultaat is echter niet erg informatief. We zijn meer geïnteresseerd in de precieze hoeveelheid heterogeniteitsvariantie die door elk niveau in ons model wordt gevangen. Het zou goed zijn om te weten hoeveel van de heterogeniteit wordt veroorzaakt door verschillen tussen participanten (niveau 1), binnen studies (niveau 2) en hoeveel door verschillen tussen studies (niveau 3).\n\n\n10.2.3 Variantie die aan elk niveau is toe te schrijven.\nIn modellen met drie niveaus wordt deze heterogeniteitsvariantie in drie delen gesplitst: individuele verschillen, een deel dat kan worden toegeschreven aan echte effectgrootteverschillen binnen clusters en een deel dat kan worden toegeschreven aan variatie tussen clusters. Er zijn dus drie \\(I^2\\) waarden, die het percentage van de totale variatie kwantificeren dat is geassocieerd met niveau 1, niveau 2 of niveau 3. De var.comp functie heeft alleen een passend rma.mv model als invoer nodig. We slaan de uitvoer op in i2 en gebruiken dan de functie summary om de resultaten af te drukken.\n\ni2 &lt;- var.comp(full.model)\nsummary(i2)\n\n        % of total variance    I2\nLevel 1            1.254966   ---\nLevel 2           39.525499 39.53\nLevel 3           59.219534 59.22\nTotal I2: 98.75% \n\n\nNo variance(niveau 1), binnen-variantie (niveau 2) is bijna \\(40\\%\\) en de tussen-variantie (level 3) is bijna \\(60\\%\\).\nWe kunnen dit visualiseren door het i2 object in de plot functie te zetten.\n\nplot(i2)\n\n\n\n\nIs een model met drie niveaus eigenlijk wel nodig? Hiervoor moeten we het drie-niveau model vergelijken met een twee-niveau model. Die vergelijking kunnen we doen met behulp van de functie anova. Laten we eerst een tweeniveaumodel maken. Dat doen we door onder method = \"REML\" de optie sigma2 = c(0, NA) toe te voegen. Dit betekent dat we de variantie op niveau 3 op 0 zetten.\n\nl3.removed &lt;- rma.mv(yi = z, \n                     V = var.z, \n                     slab = author,\n                     data = Chernobyl,\n                     random = ~ 1 | author/es.id, \n                     test = \"t\", \n                     method = \"REML\",\n                     sigma2 =  c(0, NA))\n\nsummary(l3.removed)\n\n\nMultivariate Meta-Analysis Model (k = 33; method: REML)\n\n  logLik  Deviance       AIC       BIC      AICc   \n-29.1742   58.3483   62.3483   65.2798   62.7621   \n\nVariance Components:\n\n            estim    sqrt  nlvls  fixed        factor \nsigma^2.1  0.0000  0.0000     14    yes        author \nsigma^2.2  0.3550  0.5959     33     no  author/es.id \n\nTest for Heterogeneity:\nQ(df = 32) = 4195.8268, p-val &lt; .0001\n\nModel Results:\n\nestimate      se    tval  df    pval   ci.lb   ci.ub      \n  0.5985  0.1051  5.6938  32  &lt;.0001  0.3844  0.8126  *** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNu is de functie anova te gebruiken door twee modellen te vergelijken. Dit geeft een \\(p\\)-waarde terug. Als nu de \\(p\\)-waarde significant is, heeft het complexere model (drie niveaus) de voorkeur. Als de \\(p\\)-waarde niet significant is, heeft het eenvoudigere model (twee niveaus) de voorkeur.\n\nanova(l3.removed, full.model)\n\n\n        df     AIC     BIC    AICc   logLik     LRT   pval        QE \nFull     3 48.2458 52.6430 49.1029 -21.1229                4195.8268 \nReduced  2 62.3483 65.2798 62.7621 -29.1742 16.1025 &lt;.0001 4195.8268 \n\n\nWe zien dat het Full (drie-niveaus) model inderdaad beter past dan het Reduced model met twee niveaus. De Akaike (AIC) en Bayesiaanse Informatie Criterium (BIC) zijn lager voor dit model, wat duidt op gunstige prestaties. De likelihood ratio test (LRT) die beide modellen vergelijkt is significant (\\(\\chi^2_1=\\) 16,1, \\(p&lt;\\) 0,001), en wijst dus in dezelfde richting.\nWe kunnen zeggen dat, hoewel het model met drie niveaus één extra parameter introduceert (d.w.z. het heeft 3 vrijheidsgraden in plaats van 2), deze extra complexiteit gerechtvaardigd lijkt. Het modelleren van de geclusterde datastructuur was waarschijnlijk een goed idee en heeft onze schatting van het gepoolde effect verbeterd.\nHoud er echter rekening mee dat er vaak goede redenen zijn om vast te houden aan een structuur met drie niveaus, zelfs als dit geen significant betere fit oplevert. Het is met name zinvol om vast te houden aan een model met drie niveaus als we denken dat het gebaseerd is op een solide theoretische onderbouwing.\n\n\n10.2.4 Subgroup analyse (moderatoren analyse) in dit drie niveau’s model\nZodra ons model op drie niveaus is ingesteld, is het ook mogelijk om de invloed van mogelijke moderatoren op het totale effect te beoordelen. Eerder in deze gids hebben we ontdekt dat subgroepanalyses kunnen worden uitgedrukt als een meta-regressiemodel met een dummycode voorspeller. Op vergelijkbare wijze kunnen we regressietermen toevoegen aan een “multilevel” model, wat leidt tot een ** mixed-effects model met drie niveaus**:\n\\[\\hat\\theta_{ij} = \\theta + \\beta x_i + \\zeta_{(2)ij} + \\zeta_{(3)j} + \\epsilon_{ij}\\]\nWaarbij \\(\\theta\\) het intercept is en \\(\\beta\\) het regressiegewicht van een voorspellende variabele \\(x\\). Als we \\(x_i\\) vervangen door een dummy, krijgen we een model dat kan worden gebruikt voor subgroepanalyses. Als \\(x\\) continu is, stelt de bovenstaande formule een meta-regressiemodel met drie niveaus voor.\nCategorische of continue voorspellers kunnen gespecificeerd worden in rma.mv met het mods argument. Het argument vereist een formule, beginnend met een tilde (~), en dan de naam van de voorspeller. Meervoudige meta-regressie is ook mogelijk door meer dan één voorspeller op te geven (bijvoorbeeld ~ var1 + var2).\nIn ons Chernobyl voorbeeld willen we controleren of correlaties verschillen afhankelijk van de totale hoeveelheid straling in het onderzochte monster (laag, gemiddeld of hoog). Deze informatie staat in de kolom `radiation`` in onze dataset. Met onderstaande code kunnen we een moderatorenmodel met drie niveaus fitten:\n\nmod.model &lt;- rma.mv(yi = z, V = var.z, \n                    slab = author, data = Chernobyl,\n                    random = ~ 1 | author/es.id, \n                    test = \"t\", method = \"REML\",\n                    mods = ~ radiation)\n\nsummary(mod.model)\n\nDe eerste belangrijke uitkomst is de Test van moderatoren. We zien dat \\(F_{2,28}\\)= 0,45, met \\(p\\)= 0,64. Dit betekent dat er geen significant verschil is tussen de subgroepen. Dit is hoe we de resultaten zouden beschrijven\n\n“De gepoolde correlatie op basis van het meta-analytische model met drie niveaus was \\(r=\\) 0,48 (95%CI: 0,25-0,66; \\(p\\) &lt; 0,001). De geschatte variantiecomponenten waren \\(0,179\\) en \\(0,119\\). Dit betekent dat \\(I^2_{Level 3}=\\) 0,179 en \\(I^2_{Level 2}=\\) 0,119. Dit betekent dat \\(I^2_{{Level 3}}=\\) 58,22% van de totale variatie kan worden toegeschreven aan tussen-cluster heterogeniteit en \\(I^2_{{Level 2}}=\\) 31,86% aan binnen-cluster heterogeniteit. We vonden dat het model met drie niveaus een significant betere fit gaf vergeleken met een model met twee niveaus waarbij heterogeniteit op niveau 3 tot nul werd beperkt (\\(I^2_1=\\) 16,10; \\(p\\)&lt; 0,001).”"
  },
  {
    "objectID": "06-forest_plots.html#theorie",
    "href": "06-forest_plots.html#theorie",
    "title": "6  De forest Plots",
    "section": "6.1 Theorie:",
    "text": "6.1 Theorie:\nHet is gebruikelijk om de resultaten van meta-analyses te visualiseren door middel van forest plots. Forest plots zijn op te vatten als een grafische weergave van de effectgrootte en het betrouwbaarheidsinterval van individuele studies en tonen ook het berekende totale effect. Ze laten het geobserveerde effect zien, het betrouwbaarheidsinterval en de gewichtsverdeling van elke studie. Ze laten ook het gepoolde effect zien dat berekend is over de studies.\nIn het Voorbeeld van een forest plot hieronder geeft een ruit het gemiddelde effect weer. De lengte van de ruit symboliseert het betrouwbaarheidsinterval van het gepoolde resultaat op de x-as. Meestal bevat een forest plot ook een verticale referentielijn die het punt op de x-as aangeeft dat gelijk is aan geen effect. In forest plots kun je ook iets laten zien over de heterogenities (zoals \\(I^2\\) of \\(\\tau^2\\) weer te geven.\n\n\n\nVoorbeeld van een forest plot\n\n\nHet is ook mogelijk om andere soorten informatie aan een forest plot toe te voegen, bijvoorbeeld de kwaliteitsbeoordeling die elke studie kreeg. Forest plots kunnen alleen resultaten weergeven die uitgaan van een vaste significantiedrempel, meestal \\(p&lt;0,05\\). Om te visualiseren hoe resultaten veranderen bij verschillende significantiedrempels, kunnen daarnaast draperieplots worden gegenereerd."
  },
  {
    "objectID": "07-subgroup_analyses.html#theorie",
    "href": "07-subgroup_analyses.html#theorie",
    "title": "7  Subgroep Analyse",
    "section": "7.1 Theorie",
    "text": "7.1 Theorie\nHoewel er verschillende manieren zijn om de heterogeniteit van een meta-analyse te beoordelen, vertellen die ons niet waarom we een overmatige variabiliteit in onze gegevens vinden. Subgroepanalyse stelt ons in staat om hypotheses te testen over waarom sommige onderzoeken een hogere of lagere effectgrootte hebben dan andere. We moeten verschillende studiekenmerken definiëren die de waargenomen effectgrootte kunnen beïnvloeden en elke studie dienovereenkomstig coderen.\nEr zijn talloze redenen waarom effectgroottes kunnen verschillen, maar we moeten ons beperken tot de redenen die van belang zijn in de context van onze analyse. Het idee achter subgroepanalyses is dat meta-analyse niet alleen gaat over het berekenen van een gemiddelde effectgrootte, maar dat het ook een hulpmiddel kan zijn om variatie in ons bewijs te onderzoeken. In subgroepanalyses zien we heterogeniteit niet alleen als hinderlijk, maar als interessante variatie die al dan niet verklaarbaar is door een wetenschappelijke hypothese. In het beste geval kan dit ons begrip van de wereld om ons heen vergroten, of op zijn minst praktische inzichten opleveren die richting geven aan toekomstige besluitvorming.\nVoor subgroepanalyses gaan we meestal uit van een fixed-effects model. Studies binnen subgroepen worden in de meeste gevallen gepoold met behulp van het random-effects model. Vervolgens wordt een \\(Q\\)-toets op basis van de algemene subgroepresultaten gebruikt om te bepalen of de groepen significant verschillen. Het subgroepanalysemodel wordt een “fixed-effects” model genoemd omdat de verschillende categorieën zelf als vast worden verondersteld. Dit betekent dat alle subgroepen worden verondersteld een gemeenschappelijke schatting van de heterogeniteit tussen de studies te delen.Ze vertegenwoordigen de enige waarden die de subgroepvariabele kan aannemen. Enkele voorbeelden van subgroepanalyses zijn: leeftijdsgroep, culturele achtergrond,controle-/interventiegroep, instrument om de uitkomst te meten, studiekwaliteit, soort, setting.\nBij het berekenen van een subgroepanalyse moeten we beslissen of afzonderlijke of gemeenschappelijke schattingen van de heterogeniteit tussen studies moeten worden gebruikt om de resultaten binnen subgroepen te poolen. Subgroepanalyses zijn geen wondermiddel en het belangrijk rekening te houden met de beperkingen en valkuilen van subgroepanalyses. Ze missen vaak de statistische power die nodig is om subgroepverschillen te detecteren. Daarom betekent een niet-significante test voor subgroepverschillen niet automatisch dat de subgroepen gelijkwaardige resultaten opleveren."
  },
  {
    "objectID": "05-between_study_heterogeneity.html#practijk",
    "href": "05-between_study_heterogeneity.html#practijk",
    "title": "5  Heterogeniteit tussen studies",
    "section": "5.2 Practijk",
    "text": "5.2 Practijk\nOok hier de onderstaande pakketten laden, het databestand ThirdWave openen en dit databestand goed bekijken.\n\nlibrary(tidyverse) # needed for 'glimpse'\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\nEr zitten acht variabelen (kolommen) in (Author, Year, TE, seTE, RiskOfBias, TypeControlGroup, InterventionDuration, InterventionType, and ModeOfDelivery) en achttien studies (rijen) in. De uitkomstmaat is TE (Treatment Effect) en de standaardfout van de uitkomstmaat is seTE (Standard Error of the Treatment Effect). De variabele Author bevat de namen van de auteurs van de studies. De uitkomstmaat is een Standardized Mean Difference (SMD), er wordt een random-effects model gebruikt met de methode REML.\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\nWe gaan het voorspellen.\n\nm.gen &lt;- update.meta(m.gen, prediction = TRUE)\n\nWe kunnen de resultaten van de meta-analyse bekijken met de summary functie.\n\nsummary(m.gen)\n\nReview:     Third Wave Psychotherapies\n\n                          SMD            95%-CI %W(random)\nCall et al.            0.7091 [ 0.1979; 1.2203]        5.0\nCavanagh et al.        0.3549 [-0.0300; 0.7397]        6.3\nDanitzOrsillo          1.7912 [ 1.1139; 2.4685]        3.8\nde Vibe et al.         0.1825 [-0.0484; 0.4133]        7.9\nFrazier et al.         0.4219 [ 0.1380; 0.7057]        7.3\nFrogeli et al.         0.6300 [ 0.2458; 1.0142]        6.3\nGallego et al.         0.7249 [ 0.2846; 1.1652]        5.7\nHazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        6.0\nHintz et al.           0.2840 [-0.0453; 0.6133]        6.9\nKang et al.            1.2751 [ 0.6142; 1.9360]        3.9\nKuhlmann et al.        0.1036 [-0.2781; 0.4853]        6.3\nLever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.6\nPhang et al.           0.5407 [ 0.0619; 1.0196]        5.3\nRasanen et al.         0.4262 [-0.0794; 0.9317]        5.1\nRatanasiripong         0.5154 [-0.1731; 1.2039]        3.7\nShapiro et al.         1.4797 [ 0.8618; 2.0977]        4.2\nSong & Lindquist       0.6126 [ 0.1683; 1.0569]        5.7\nWarnecke et al.        0.6000 [ 0.1120; 1.0880]        5.2\n\nNumber of studies: k = 18\n\n                             SMD            95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [ 0.3782; 0.7760] 6.12 &lt; 0.0001\nPrediction interval              [-0.0572; 1.2115]              \n\nQuantifying heterogeneity:\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n- Prediction interval based on t-distribution (df = 16)\n\n\nDit is wat er gerapporteerd kan worden:\n&gt; “De heterogeniteitsvariantie tussen studies werd geschat op \\(\\tau^2\\) = 0,08 (95%CI: 0,03-0,35), met een \\(I^2\\)-waarde van 63% (95%CI: 38-78%). Het voorspellingsinterval varieerde van \\(g\\) = -0,06 tot 1,21, wat aangeeft dat negatieve interventie-effecten niet kunnen worden uitgesloten voor toekomstige studies.”\nOm uitschieters te vinden hebben we de functie find.outliers gebruikt, die een object nodig heeft dat is gemaakt door de functie metagen.\n\nfind.outliers(m.gen)\n\nIdentified outliers (random-effects model) \n------------------------------------------ \n\"DanitzOrsillo\", \"Shapiro et al.\" \n \nResults with outliers removed \n----------------------------- \nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 16\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.4528 [0.3257; 0.5800] 7.59 &lt; 0.0001\nPrediction interval              [0.1687; 0.7369]              \n\nQuantifying heterogeneity:\n tau^2 = 0.0139 [0.0000; 0.1032]; tau = 0.1180 [0.0000; 0.3213]\n I^2 = 24.8% [0.0%; 58.7%]; H = 1.15 [1.00; 1.56]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 19.95   15  0.1739\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 15)\n- Prediction interval based on t-distribution (df = 14)\n\n\nWe zien dat de find.outliers functie twee uitschieters detecteerde, “DanitzOrsillo” en “Shapiro et al.”. Het {dmetar} pakket bevat ook een functie genaamd InfluenceAnalysis, waarmee we deze verschillende invloedsdiagnoses kunnen berekenen met behulp van één functie. De functie kan worden gebruikt voor elk type meta-analyseobject dat is gemaakt door {meta} functies. We slaan de resultaten van de functie op in een object genaamd m.gen.inf.\n\nm.gen.inf &lt;- InfluenceAnalysis(m.gen, random = TRUE)\n\n[===========================================================================] DONE \n\n\nDit creëert een baujat plot, die een grafische weergave geeft van de invloed van elke studie op de heterogeniteit van de meta-analyse.\n\nplot(m.gen.inf, \"baujat\")\n\nWarning: ggrepel: 12 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\nDe volgende plot bevat verschillende invloedsdiagnoses voor elk van onze onderzoeken. Deze kunnen worden uitgezet met deze code:\n\nplot(m.gen.inf, \"influence\")\n\n\n\n\nHet {dmetar} pakket bevat, tenslotte, ook een functie genaamd InfluenceAnalysis, waarmee we deze resultaten kunnen berekenen met behulp van de ‘leave-one-out’-methode. De eerste is gesorteerd op effectgrootte, de tweede op heterogeniteit.\n\nplot(m.gen.inf, \"es\")\n\n\n\nplot(m.gen.inf, \"i2\")"
  },
  {
    "objectID": "06-forest_plots.html#praktijk",
    "href": "06-forest_plots.html#praktijk",
    "title": "6  De forest Plots",
    "section": "6.2 Praktijk:",
    "text": "6.2 Praktijk:\nHet meta-pakket in R is een veelgebruikte tool voor het maken van forest plots. Het heeft veel functies en de opmaak van de plots kan worden aangepast aan de wensen van de gebruiker.\nWe beginnen met het databestand zoals eerder omhoog gehaald.\n\nlibrary(tidyverse) # voor databewerking\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)    # voor de data\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)      # voor de meta-analyse\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\nm.gen bevat de resultaten van de meta-analyse. We kunnen de resultaten van de meta-analyse visualiseren met de forest()-functie.\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\nWe kunnen een forest plot maken voor elk type {meta} meta-analyse object (bijv. resultaten van metagen, metacont, of metabin) met behulp van de forest.meta-functie. We hoeven alleen maar forest.meta te voorzien van ons {meta} object en er wordt een plot gemaakt.\n\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftlabs = c(\"Author\", \"g\", \"SE\"))\n\n\n\n\nEr zijn allerlei argumenten in dit pakket om de forest plots verder aan te passen. Zo kunnen we de plot verbeteren door een kolom toe te voegen die het bias-risico van elke studie weergeeft. De dataset ThirdWave, die we gebruikten om m.gen te genereren, bevat een kolom met de naam RiskOfBias, waarin de beoordeling van het risico van vertekening van elke studie is opgeslagen.\nWe kunnen het argument leftcols gebruiken om de kolom aan de plot toe te voegen. Dit resulteert in de volgende code en de informatie van elke studie is toegevoegd.\n\nforest.meta(m.gen, \n            sortvar = TE,\n            prediction = TRUE, \n            print.tau2 = FALSE,\n            leftcols = c(\"studlab\", \"TE\", \"seTE\", \"RiskOfBias\"),\n            leftlabs = c(\"Author\", \"g\", \"SE\", \"Risk of Bias\"))\n\n\n\n\nEr zijn ook twee voorgeprogrammeerde lay-outs voor forest plots:die van JAMA en van Cochrane. We kunnen de lay-out van de plot aanpassen met behulp van de layout-functie. Hier bijvoorbeeld de JAMA-lay-out.\n\nforest.meta(m.gen, layout = \"JAMA\")\n\n\n\n\nJe kunt de forest plots op verschillende manieren opslaan (bijvoorbeeld PDF, PNG, SVG). Hier slaan we de JAMA forest plot op als een pdf in onze img-folder.\n\npdf(\"img/forest_plot.pdf\")\nforest.meta(m.gen, layout = \"JAMA\")\ndev.off()\n\nquartz_off_screen \n                2 \n\n\nBehalve de forest plot zijn er ook nog andere manieren op de resultaten te visualiseren (bv. draperie plots)."
  },
  {
    "objectID": "07-subgroup_analyses.html#praktijk",
    "href": "07-subgroup_analyses.html#praktijk",
    "title": "7  Subgroep Analyse",
    "section": "7.2 Praktijk",
    "text": "7.2 Praktijk\nHet uitvoeren van een subgroepanalyse met behulp van het {meta} pakket is relatief eenvoudig. In elke meta-analysefunctie in {meta} kan het argument subgroep worden gespecificeerd. Dit vertelt de functie welke effectgrootte in welke subgroep valt en voert een subgroepanalyse uit. Het argument subgroep accepteert diverse soorten variabelen. Het enige waar we op moeten letten is dat studies in dezelfde subgroep absoluut identieke labels hebben.\nLaten we het databestand ThirdWave gebruiken om een subgroepanalyse uit te voeren en kjken naar de kolommen author en RiskofBias.\n\nlibrary(tidyverse) # voor databewerking\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)    # voor de data\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)      # voor de meta-analyse\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nhead(ThirdWave[,c(\"Author\", \"RiskOfBias\")])\n\n           Author RiskOfBias\n1     Call et al.       high\n2 Cavanagh et al.        low\n3   DanitzOrsillo       high\n4  de Vibe et al.        low\n5  Frazier et al.        low\n6  Frogeli et al.        low\n\n\nLaten we eerst m.gen aanmaken en vervolgens de subgroepanalyse uitvoeren.\n\nm.gen &lt;- metagen(TE = TE,\n                 seTE = seTE,\n                 studlab = Author,\n                 data = ThirdWave,\n                 sm = \"SMD\",\n                 fixed = FALSE,\n                 random = TRUE,\n                 method.tau = \"REML\",\n                 hakn = TRUE,\n                 title = \"Third Wave Psychotherapies\")\n\n\nupdate.meta(m.gen, \n            subgroup = RiskOfBias, \n            tau.common = FALSE)\n\nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 18\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [0.3782; 0.7760] 6.12 &lt; 0.0001\n\nQuantifying heterogeneity:\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nResults for subgroups (random effects model (HK)):\n                    k    SMD           95%-CI  tau^2    tau     Q   I^2\nRiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%\nRiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%\n\nTest for subgroup differences (random effects model (HK)):\n                  Q d.f. p-value\nBetween groups 2.84    1  0.0917\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n\n\nIn de uitvoer zien we een nieuw gedeelte genaamd Results for subgroups. Dit deel van de uitvoer toont de gepoolde effectgrootte afzonderlijk voor elke subgroep. We zien dat er k=7 studies zijn met een hoog risico op vertekening en 11 met een laag risico op vertekening. De geschatte heterogeniteit tussen studies verschilt aanzienlijk, met \\(I^2\\)=77% in studies met een hoog risico op vertekening, maar slechts 26% in studies met een laag risico. Met \\(g\\)=0,43 is de effectschatting in studies met een laag vertekeningsrisico kleiner dan in studies met een hoog vertekeningsrisico. Dit is een veel voorkomende bevinding, omdat vertekende studies de effecten van een behandeling eerder overschatten.\nMaar is het verschil statistisch significant? We kunnen dit controleren door te kijken naar de resultaten van de Test for subgroup differences. Dit toont ons de \\(Q\\)-test, die in ons voorbeeld met 2 subgroepen gebaseerd is op één vrijheidsgraad. De \\(p\\)-waarde van de test is 0,09, wat groter is dan de conventionele significantiedrempel, maar nog steeds een verschil op trendniveau aangeeft.We kunnen de resultaten ook controleren als we uitgaan van een gemeenschappelijke \\(\\tau^2\\)-schatting in beide subgroepen. We hoeven alleen tau.common op TRUE te zetten.\n\nupdate.meta(m.gen, subgroup = RiskOfBias, tau.common = TRUE)\n\nReview:     Third Wave Psychotherapies\n\nNumber of studies: k = 18\n\n                             SMD           95%-CI    t  p-value\nRandom effects model (HK) 0.5771 [0.3782; 0.7760] 6.12 &lt; 0.0001\n\nQuantifying heterogeneity:\n tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]\n I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]\n\nQuantifying residual heterogeneity:\n tau^2 = 0.0691 [0.0208; 0.3268]; tau = 0.2630 [0.1441; 0.5717]\n I^2 = 59.3% [30.6%; 76.1%]; H = 1.57 [1.20; 2.05]\n\nTest of heterogeneity:\n     Q d.f. p-value\n 45.50   17  0.0002\n\nResults for subgroups (random effects model (HK)):\n                    k    SMD           95%-CI  tau^2    tau     Q   I^2\nRiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%\nRiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%\n\nTest for subgroup differences (random effects model (HK)):\n                   Q d.f. p-value\nBetween groups  1.79    1  0.1814\nWithin groups  39.31   16  0.0010\n\nDetails on meta-analytical method:\n- Inverse variance method\n- Restricted maximum-likelihood estimator for tau^2\n  (assuming common tau^2 in subgroups)\n- Q-Profile method for confidence interval of tau^2 and tau\n- Hartung-Knapp adjustment for random effects model (df = 17)\n\n\nWe zien dat de geschatte heterogeniteitsvariantie tussen studies \\(\\tau^2\\)= 0,069 is, en identiek in beide subgroepen. We hebben twee \\(Q\\)-tests: één tussen groepen (de eigenlijke subgroeptoets) en één voor de heterogeniteit binnen de subgroepen. Net als in een normale meta-analyse geeft dit laatste simpelweg aan dat er een overmatige variabiliteit is in de subgroepen (\\(p\\)= 0,001). De test van subgroepverschillen geeft opnieuw aan dat er geen significant verschil is tussen studies met een laag versus hoog risico op vertekening (p= 0,181).\nDe resultaten van subgroepanalyses worden meestal gerapporteerd in een tabel met het geschatte effect en de heterogeniteit in elke subgroep, evenals de p-waarde van de test voor subgroepverschillen.\n\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\n\n\n\n\n\n$g$\n95\\%CI\n$p$\n$I^2$\n95\\%CI\n$p$subgroup\n\n\n\n\nRisk of Bias\n\n\n\n\n\n0.092\n\n\n- High\n0.81\n0.28-1.34\n0.009\n0.77\n0.51-0.89\n\n\n\n- Low\n0.43\n0.28-0.58\n$&lt;$ 0.001\n0.25\n0.00-0.63"
  },
  {
    "objectID": "13-bayesian_meta-analysis.html#theorie",
    "href": "13-bayesian_meta-analysis.html#theorie",
    "title": "13  Bayesian Meta-Analysis",
    "section": "13.1 Theorie",
    "text": "13.1 Theorie\nHoewel meta-analyses meestal worden uitgevoerd met behulp van frequentistische statistieken (zoals in de vorige hoofdstukken die werden uitgevoerd met de meta en metafor-pakketten), is het ook mogelijk om Bayesiaanse meta-analyses uit te voeren (die met andere pakketten worden uitgevoerd, zoals in dit hoofdstuk met het brms-pakket).\nEr zitten enkele voordelen aan Bayesiaanse meta-analyse:\n\nBayesiaanse methoden maken het mogelijk om de onzekerheid in onze schatting van \\(\\tau^2\\). Ze kunnen ook superieur zijn in het schatten van gepoolde effecten, vooral als het aantal geïncludeerde onderzoeken klein is (wat in de praktijk vaak het geval is).\nBayesiaanse methoden produceren volledige posterior verdelingen voor zowel \\(\\mu\\) en \\(\\tau^2\\). Dit maakt het mogelijk om de exacte kans te berekenen dat \\(\\mu\\) of \\(\\tau^2\\) kleiner of groter is dan een bepaalde waarde. Dit in tegenstelling tot frequentistische methoden, waarbij we alleen betrouwbaarheidsintervallen berekenen. Echter, (95%) betrouwbaarheidsintervallen stellen alleen dat, als de gegevensbemonstering vele, vele keren zou worden herhaald, de werkelijke waarde van een populatieparameter (zoals \\(\\mu\\) of \\(\\tau^2\\)) in 95% van de steekproeven binnen het bereik van het betrouwbaarheidsinterval zou vallen. Ze vertellen ons niet hoe groot de kans is dat de ware parameter tussen twee gespecificeerde waarden ligt.\nBayesiaanse methoden stellen ons in staat om voorkennis (prior knowledge) en aannames te integreren bij het berekenen van meta-analyses.\n\nBayesiaanse meta-analyse wordt in dit hoofdstuk gebaseerd op het Bayesiaanse hiërarchische model. De kernprincipes van dit model zijn identiek aan het “conventionele” random-effects model. Het verschil is echter dat er (informatieve, zwak informatieve of niet-informatieve) prior distributies worden aangenomen voor \\(mu\\)μ en \\(tau^2\\).\nVoor Bayesiaanse meta-analyse-modellen is het meestal een goed idee om uit te gaan van zwakke informatieve priors. Zwakke informatieve priors worden gebruikt om een zwak geloof weer te geven dat sommige waarden geloofwaardiger zijn dan andere. Voor het specificeren van de prior-verdeling voor de heterogeniteitsvariantie \\(\\tau^2\\) tussen studies kan de half-Cauchy distributies worden gebruikt. Half-Cauchy distributies zijn bijzonder geschikt voor deze taak omdat ze alleen gedefinieerd zijn voor positieve waarden en een zwaardere staart (langere uiterste waarden) hebben. Dit kan worden gebruikt om aan te geven dat zeer hoge waarden van \\(\\tau^2\\) minder waarschijnlijk zijn, maar nog steeds goed mogelijk.\nBij het draaien van Bayesiaanse meta-analysemodellen is het belangrijk om (1) altijd te controleren of het model voldoende iteraties bevat om te convergeren (bijvoorbeeld door de \\(hat{R}\\) waarden te controleren), en om (2) sensitiviteits analyses uit te voeren met verschillende prioriteitspecificaties om de invloed op de resultaten te evalueren."
  },
  {
    "objectID": "13-bayesian_meta-analysis.html#praktijk",
    "href": "13-bayesian_meta-analysis.html#praktijk",
    "title": "13  Bayesian Meta-Analysis",
    "section": "13.2 Praktijk",
    "text": "13.2 Praktijk\n\n13.2.1 Het model draaien\nNu gaan we een Bayesiaanse meta-analyse uitvoeren en dat doen we met het brms-pakket. Dat moet op jouw computer geïnstalleerd zijn. Om brms op jouw computer te krijgen, moet je overigens wel eerst stan op jouw computer hebben staan. Zie hier de handleiding.\nWe laden brms eerst.\n\nlibrary(brms)\n\nLoading required package: Rcpp\n\n\nLoading 'brms' package (version 2.20.4). Useful instructions\ncan be found by typing help('brms'). A more detailed introduction\nto the package is available through vignette('brms_overview').\n\n\n\nAttaching package: 'brms'\n\n\nThe following object is masked from 'package:stats':\n\n    ar\n\n\n1. Importeren en bekijken van dataset\n\nlibrary(tidyverse) # voor databewerking\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)    # voor de data\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)      # voor de meta-analyse\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\nIn Bayesiaanse modellen is het belangrijk om priors te specificeren. We specificeren hier een prior voor de intercept en de standaarddeviatie van de effectgroottes.\n\npriors &lt;- c(prior(normal(0,1), class = Intercept),\n            prior(cauchy(0,0.5), class = sd))\n\nNu kunnen we gaan modelleren.\n2. Modelleren In de syntax hieronder wordt de formule voor het model gespecificeerd. Het {brms} pakket gebruikt een regressieformule notatie, waarin een uitkomst (in ons geval een waargenomen effectgrootte) \\(y\\) wordt voorspeld door een of meer voorspellers \\(x\\). Een tilde (\\({\\sim}\\)) wordt gebruikt om aan te geven dat er een voorspellende relatie is: \\(y {\\sim} x\\).\nMeta-analyses zijn enigszins speciaal, omdat we geen variabele hebben die de effectgrootte voorspelt (tenzij we een meta-regressie uitvoeren). Dit betekent dat \\(x\\) moet worden vervangen door 1, wat duidt op een intercept-only model. Bovendien kunnen we niet simpelweg de effectgrootte van elke studie in \\(y\\) gebruiken. We moeten ook studies met een hogere precisie (d.w.z. steekproefgrootte) een groter gewicht geven. Dit kan worden gedaan door \\(y|se(se_y)\\) te gebruiken in plaats van alleen y, waarbij het \\(se(se_y)\\) deel staat voor de standaardfout van elke effectgrootte y in onze dataset.\nAls we een random-effectmodel willen gebruiken, is de laatste stap het toevoegen van een random-effectterm \\((1|studie)\\) aan de rechterkant van de formule. Dit specificeert dat de effectgroottes in \\(y\\) verondersteld worden genest te zijn binnen studies, waarvan de ware effecten zelf willekeurige trekkingen zijn uit een overkoepelende populatie van ware effectgroottes. Als we een model met vast effect willen gebruiken, kunnen we deze term gewoon weglaten. De algemene volledige formule voor een random-effect model ziet er dan als volgt uit: \\(y|se(se_y) ~ 1 + (1|random)\\).\nLet op, onderstaande code kan enige tijd duren om uit te voeren.\n\nm.brm &lt;- brm(TE|se(seTE) ~ 1 + (1|Author),\n             data = ThirdWave,\n             prior = priors,\n             iter = 4000)\n\nCompiling Stan program...\n\n\nTrying to compile a simple C file\n\n\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nclang -mmacosx-version-min=10.13 -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.2/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/usr/local/include   -fPIC  -Wall -g -O2  -c foo.c -o foo.o\nIn file included from &lt;built-in&gt;:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:88:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name 'namespace'\nnamespace Eigen {\n^\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected ';' after top level declarator\nnamespace Eigen {\n               ^\n               ;\nIn file included from &lt;built-in&gt;:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Dense:1:\n/Library/Frameworks/R.framework/Versions/4.2/Resources/library/RcppEigen/include/Eigen/Core:96:10: fatal error: 'complex' file not found\n#include &lt;complex&gt;\n         ^~~~~~~~~\n3 errors generated.\nmake: *** [foo.o] Error 1\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.5e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.45 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 1: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 1: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 1: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 1: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 1: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 1: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 1: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 1: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 1: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 1: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 1: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.355 seconds (Warm-up)\nChain 1:                0.334 seconds (Sampling)\nChain 1:                0.689 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 8e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 2: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 2: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 2: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 2: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 2: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 2: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 2: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 2: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 2: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 2: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 2: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.356 seconds (Warm-up)\nChain 2:                0.406 seconds (Sampling)\nChain 2:                0.762 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 3: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 3: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 3: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 3: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 3: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 3: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 3: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 3: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 3: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 3: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 3: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.372 seconds (Warm-up)\nChain 3:                0.349 seconds (Sampling)\nChain 3:                0.721 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 8e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 4000 [  0%]  (Warmup)\nChain 4: Iteration:  400 / 4000 [ 10%]  (Warmup)\nChain 4: Iteration:  800 / 4000 [ 20%]  (Warmup)\nChain 4: Iteration: 1200 / 4000 [ 30%]  (Warmup)\nChain 4: Iteration: 1600 / 4000 [ 40%]  (Warmup)\nChain 4: Iteration: 2000 / 4000 [ 50%]  (Warmup)\nChain 4: Iteration: 2001 / 4000 [ 50%]  (Sampling)\nChain 4: Iteration: 2400 / 4000 [ 60%]  (Sampling)\nChain 4: Iteration: 2800 / 4000 [ 70%]  (Sampling)\nChain 4: Iteration: 3200 / 4000 [ 80%]  (Sampling)\nChain 4: Iteration: 3600 / 4000 [ 90%]  (Sampling)\nChain 4: Iteration: 4000 / 4000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.371 seconds (Warm-up)\nChain 4:                0.328 seconds (Sampling)\nChain 4:                0.699 seconds (Total)\nChain 4: \n\n\n3. Resultaten bekijken Nu kun je de resultaten bekijken. Maar kijk wel of het model heeft geconvergeerd (dat betekent dat je er zeker van bent dat het MCMC algoritme de optimale oplossing gevonden heeft). Bekijk de \\(hat{R}\\) waarden. De \\(hat{R}\\) waarden geven aan hoeveel de ketens van het model van elkaar verschillen. Als de \\(hat{R}\\) waarden dicht bij 1 liggen, is het model geconvergeerd.\n\nsummary(m.brm)\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: TE | se(seTE) ~ 1 + (1 | Author) \n   Data: ThirdWave (Number of observations: 18) \n  Draws: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;\n         total post-warmup draws = 8000\n\nGroup-Level Effects: \n~Author (Number of levels: 18) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.29      0.10     0.12     0.52 1.00     2605     3363\n\nPopulation-Level Effects: \n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     0.57      0.09     0.39     0.76 1.00     4478     4194\n\nFamily Specific Parameters: \n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.00      0.00     0.00     0.00   NA       NA       NA\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n4. Valideren Je kunt de resultaten valideren door de posterior predictive checks te bekijken. Dit zijn de voorspelde effectgroottes van het model. Voor validatie kunnen we verwachten dat de replicaties (blauwe lijnen) ongeveer gelijk zijn aan die van de waargenomen gegevens (zwarte lijn). Dit kan eenvoudig worden gecontroleerd met de uitvoer van de functie pp_check.\n\npp_check(m.brm)\n\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n\n\n\n\n\n5. Interpreteren van de resultaten\nWe kunnen beginnen met het interpreteren van de resultaten door eerst te kijken naar de effecten op groepsniveau in onze samenvattende uitvoer. Dit gedeelte is gereserveerd voor het willekeurige effect dat we in onze formule hebben gedefinieerd. Omdat we een random-effect meta-analysemodel hebben toegepast, is de variabele ~Author, die de individuele studies aangeeft, gemodelleerd met een random intercept.\nZoals we eerder beschreven, vertegenwoordigt dit onze aanname op niveau 2 dat elke studie zijn eigen “ware” effectgrootte heeft, die is genomen uit een overkoepelende verdeling van ware effectgroottes. We zien ook dat ons effect op groepsniveau 18 niveaus heeft, wat overeenkomt met de \\(K= 18\\) onderzoeken in onze gegevens.\n\nranef(m.brm)\n\n$Author\n, , Intercept\n\n                          Estimate Est.Error         Q2.5       Q97.5\nCall et al.             0.07189163 0.1936376 -0.309127168  0.46717641\nCavanagh et al.        -0.14025633 0.1780704 -0.503539985  0.19795655\nDanitzOrsillo           0.48972884 0.2863537  0.001300353  1.09783927\nde Vibe et al.         -0.31951422 0.1438052 -0.618468804 -0.04759875\nFrazier et al.         -0.11351230 0.1504414 -0.419397959  0.16581592\nFrogeli et al.          0.03894014 0.1726801 -0.303395102  0.38477523\nGallego et al.          0.09083868 0.1781655 -0.253086814  0.45645967\nHazlett-Stevens & Oren -0.02571507 0.1781782 -0.385061025  0.32151043\nHintz et al.           -0.20110673 0.1635725 -0.537159537  0.10170118\nKang et al.             0.28523892 0.2440696 -0.149691728  0.80560147\nKuhlmann et al.        -0.30539003 0.1825887 -0.687654040  0.03201563\nLever Taylor et al.    -0.10432654 0.1865457 -0.493461745  0.25241641\nPhang et al.           -0.01604668 0.1916494 -0.405906674  0.35900337\nRasanen et al.         -0.07866751 0.2007168 -0.490698099  0.30207909\nRatanasiripong         -0.02373599 0.2320420 -0.509482081  0.43393135\nShapiro et al.          0.40341236 0.2581403 -0.043087679  0.93980982\nSong & Lindquist        0.02229791 0.1849255 -0.342200588  0.39215805\nWarnecke et al.         0.01353748 0.1952486 -0.379068846  0.39691994\n\n\nHet volgende deel van de uitvoer dat we kunnen interpreteren zijn de effecten op populatieniveau. Dit deel geeft de “vaste” populatieparameters weer die we hebben gemodelleerd. In ons geval is dit \\(\\mu\\) de totale effectgrootte van onze meta-analyse.\nIn de uitvoer zien we dat de schatting een (voor bias gecorrigeerde) SMD van \\(0,57\\) is, met het 95% geloofwaardige interval variërend van \\(95%CrI: 0,39-0,76\\). Dit geeft aan dat de interventies die in deze meta-analyse zijn onderzocht een matig groot algeheel effect hebben.\nOmdat dit een Bayesiaans model is, vinden we hier geen p-waarden. Maar ons voorbeeld zou moeten onderstrepen dat we ook redelijke conclusies kunnen trekken zonder onze toevlucht te hoeven nemen tot klassieke significantietests.\nWat we goed kunnen doen in een Bayesiaanse, maar niet in een frequentistische meta-analyse, is de parameters die we willen schatten probabilistisch modelleren. Het Bayesiaanse model schat niet alleen de parameters die van belang zijn, maar een hele posterior verdeling voor \\(\\tau^2\\) en \\(\\mu\\), waar we vrij eenvoudig toegang toe hebben. We hoeven alleen maar de posterior_samples functie te gebruiken.\n\npost.samples &lt;- posterior_samples(m.brm, c(\"^b\", \"^sd\"))\n\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for\nrecommended alternatives.\n\nnames(post.samples)\n\n[1] \"b_Intercept\"          \"sd_Author__Intercept\"\n\n\nHet resulterende dataframe bevat twee kolommen: b_Intercept, de posterior steekproefgegevens voor de gepoolde effectgrootte, en sd_Author_Intercept, die voor de heterogeniteit τ tussen de studies. We hernoemen de kolommen smd en tau om de naam informatiever te maken.\n\nnames(post.samples) &lt;- c(\"smd\", \"tau\")\n\nNu kunnen we density plots maken van deze posterior distributies. We gebruiken het ggplot pakket.\n\nggplot(aes(x = smd), data = post.samples) +\n  geom_density(fill = \"lightblue\",                # set the color\n               color = \"lightblue\", alpha = 0.7) +  \n  geom_point(y = 0,                               # add point at mean\n             x = mean(post.samples$smd)) +\n  labs(x = expression(italic(SMD)),\n       y = element_blank()) +\n  theme_minimal()\n\n\n\nggplot(aes(x = tau), data = post.samples) +\n  geom_density(fill = \"lightgreen\",               # set the color\n               color = \"lightgreen\", alpha = 0.7) +  \n  geom_point(y = 0, \n             x = mean(post.samples$tau)) +        # add point at mean\n    labs(x = expression(tau),\n       y = element_blank()) +\n  theme_minimal()\n\n\n\n\nWe kunnen ook probabilistische uitspraken doen over de kans dat het ware effect groter of kleiner is dan een bepaalde drempelwaarde (bv dat het gepoolde effect kleiner is dan 0.30). We kunnen dit doen door de ecdf-functie te gebruiken.\n\nsmd.ecdf &lt;- ecdf(post.samples$smd)\nsmd.ecdf(0.3)\n\n[1] 0.001625\n\n\nWe zien dat met 0,21% de kans dat ons gepoolde effect kleiner is dan 0,30 heel erg klein is. Ervan uitgaande dat de cut-off geldig is, zou dit betekenen dat het totale effect van de interventie dat we in deze meta-analyse vinden zeer waarschijnlijk zinvol is.\n6. Een forest plot genereren Forest plots kunnen nog niet in brms worden gemaakt. We doen het zelf en doen wat bewerkingen via tidybayes.\nLaad deze pakketten.\n\nlibrary(tidybayes)\n\n\nAttaching package: 'tidybayes'\n\n\nThe following objects are masked from 'package:brms':\n\n    dstudent_t, pstudent_t, qstudent_t, rstudent_t\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggridges)\n\n\nAttaching package: 'ggridges'\n\n\nThe following objects are masked from 'package:tidybayes':\n\n    scale_point_color_continuous, scale_point_color_discrete,\n    scale_point_colour_continuous, scale_point_colour_discrete,\n    scale_point_fill_continuous, scale_point_fill_discrete,\n    scale_point_size_continuous\n\nlibrary(glue)\nlibrary(stringr)\nlibrary(forcats)\n\nVoordat we de plot kunnen genereren, moeten we de gegevens voorbereiden. We moeten de posterior distributie voor elke studie afzonderlijk extraheren (aangezien forest plots ook de specifieke effectgrootte van elke studie weergeven). Om dit te bereiken, kunnen we de spread_draws functie in het {tidybayes} pakket gebruiken. De functie heeft drie argumenten nodig als invoer: ons gepaste {brms} model, de random-effects factor waarmee de resultaten moeten worden geïndexeerd en de parameter die we willen extraheren (hier b_Intercept, omdat we de vaste term willen extraheren: de effectgrootte).\nMet behulp van de mutate-functie in {dplyr} berekenen we de werkelijke effectgrootte van elke studie door de gepoolde effectgrootte b_Intercept op te tellen bij de geschatte afwijking van elke studie. We slaan het resultaat op als study.draws.\n\nstudy.draws &lt;- spread_draws(m.brm, r_Author[Author,], b_Intercept) %&gt;% \n  mutate(b_Intercept = r_Author + b_Intercept)\n\nVervolgens willen we de verdeling van het gepoolde effect op een vergelijkbare manier genereren (omdat in forest plots het samenvattende effect meestal in de laatste rij wordt weergegeven). Daarom passen we de code van hiervoor enigszins aan, waarbij we het tweede argument laten vallen om alleen het gepoolde effect te krijgen. De oproep tot muteren voegt alleen een extra kolom toe met de naam “Author”. We slaan het resultaat op als pooled.effect.draws.\n\npooled.effect.draws &lt;- spread_draws(m.brm, b_Intercept) %&gt;% \n  mutate(Author = \"Pooled Effect\")\n\nVervolgens binden we study.draws en pooled.effect.draws samen in één dataframe. Vervolgens starten we weer een pipe, waarbij we eerst ungroup aanroepen en vervolgens mutate gebruiken om (1) de studielabels op te schonen (d.w.z. punten vervangen door spaties) en (2) de studiefactorniveaus te herschikken op effectgrootte (hoog naar laag). Het resultaat zijn de gegevens die we nodig hebben voor het plotten, die we opslaan als forest.data.\n\nforest.data &lt;- bind_rows(study.draws, \n                         pooled.effect.draws) %&gt;% \n   ungroup() %&gt;%\n   mutate(Author = str_replace_all(Author, \"[.]\", \" \")) %&gt;% \n   mutate(Author = reorder(Author, b_Intercept))\n\nTen slotte moet de forest plot ook de effectgrootte (SMD en betrouwbaarheidsinterval) van elke studie weergeven. Om dit te doen, gebruiken we onze nieuw gegenereerde forest.data dataset, groeperen deze op Author en gebruiken vervolgens de mean_qi functie om deze waarden te berekenen. We slaan de uitvoer op als forest.data.summary.\n\nforest.data.summary &lt;- group_by(forest.data, Author) %&gt;% \n  mean_qi(b_Intercept)\n\nNu kunnen we een forest plot maken met ggplot.\n\nggplot(aes(b_Intercept, \n           relevel(Author, \"Pooled Effect\", \n                   after = Inf)), \n       data = forest.data) +\n  \n  # Add vertical lines for pooled effect and CI\n  geom_vline(xintercept = fixef(m.brm)[1, 1], \n             color = \"grey\", size = 1) +\n  geom_vline(xintercept = fixef(m.brm)[1, 3:4], \n             color = \"grey\", linetype = 2) +\n  geom_vline(xintercept = 0, color = \"black\", \n             size = 1) +\n  \n  # Add densities\n  geom_density_ridges(fill = \"blue\", \n                      rel_min_height = 0.01, \n                      col = NA, scale = 1,\n                      alpha = 0.8) +\n  geom_pointintervalh(data = forest.data.summary, \n                      size = 1) +\n  \n  # Add text and labels\n  geom_text(data = mutate_if(forest.data.summary, \n                             is.numeric, round, 2),\n    aes(label = glue(\"{b_Intercept} [{.lower}, {.upper}]\"), \n        x = Inf), hjust = \"inward\") +\n  labs(x = \"Standardized Mean Difference\", # summary measure\n       y = element_blank()) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: 'geom_pointintervalh' is deprecated.\nUse 'geom_pointinterval' instead.\nSee help(\"Deprecated\") and help(\"tidybayes-deprecated\").\n\n\nPicking joint bandwidth of 0.0271"
  },
  {
    "objectID": "11-seq_meta-analysis.html#theorie",
    "href": "11-seq_meta-analysis.html#theorie",
    "title": "11  Structural Equation Modeling Meta-Analysis",
    "section": "11.1 Theorie",
    "text": "11.1 Theorie\nStructural Equation Modeling (SEM) is een statistische techniek die kan worden gebruikt om complexe relaties tussen waargenomen (d.w.z. manifeste) en niet-waargenomen (d.w.z. latente) variabelen te testen.\nMeta-analyse is gebaseerd op een multilevel model, en kan daarom ook worden geformuleerd vanuit een SEM perspectief. Dit kan worden gebruikt om random-effects meta-analyses te “repliceren” als structurele vergelijkingsmodellen. Belangrijker is echter dat dit ons in staat stelt om meta-analyses uit te voeren die complexere relaties tussen waargenomen effectgrootten modelleren.\nMeta-analytische SEM kan bijvoorbeeld worden toegepast om multivariate meta-analyses uit te voeren. In multivariate meta-analyses worden twee of meer uitkomsten gezamenlijk geschat, waarbij rekening wordt gehouden met de correlatie tussen beide uitkomstmaten.\nEen andere toepassing van meta-analytische SEM is confirmatory factor analysis. Om de geschiktheid van een voorgesteld factormodel voor alle geïncludeerde onderzoeken te testen, moet een tweestapsprocedure worden gebruikt. In de eerste fase worden correlatiematrices van individuele studies samengevoegd. Vervolgens wordt deze gepoolde correlatiematrix gebruikt om de veronderstelde SEM te fitten."
  },
  {
    "objectID": "11-seq_meta-analysis.html#praktijk",
    "href": "11-seq_meta-analysis.html#praktijk",
    "title": "11  Structural Equation Modeling Meta-Analysis",
    "section": "11.2 Praktijk",
    "text": "11.2 Praktijk\n\n11.2.1 Multivariate Meta-Analyse\n\nlibrary(metaSEM)   # voor SEM\n\nLoading required package: OpenMx\n\n\nOpenMx may run faster if it is compiled to take advantage of multiple cores.\n\n\n\"SLSQP\" is set as the default optimizer in OpenMx.\n\n\nmxOption(NULL, \"Gradient algorithm\") is set at \"central\".\n\n\nmxOption(NULL, \"Optimality tolerance\") is set at \"6.3e-14\".\n\n\nmxOption(NULL, \"Gradient iterations\") is set at \"2\".\n\nlibrary(tidyverse) # voor databewerking\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ purrr::rerun()  masks metaSEM::rerun()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(dmetar)    # voor de data\n\nRegistered S3 methods overwritten by 'meta':\n  method             from   \n  print.meta         metaSEM\n  print.summary.meta metaSEM\n  summary.meta       metaSEM\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(meta)      # voor de meta-analyse\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nAttaching package: 'meta'\n\nThe following objects are masked from 'package:metaSEM':\n\n    print.summary.meta, summary.meta\n\ndata(ThirdWave)\nglimpse(ThirdWave)\n\nRows: 18\nColumns: 8\n$ Author               &lt;chr&gt; \"Call et al.\", \"Cavanagh et al.\", \"DanitzOrsillo\"…\n$ TE                   &lt;dbl&gt; 0.7091362, 0.3548641, 1.7911700, 0.1824552, 0.421…\n$ seTE                 &lt;dbl&gt; 0.2608202, 0.1963624, 0.3455692, 0.1177874, 0.144…\n$ RiskOfBias           &lt;chr&gt; \"high\", \"low\", \"high\", \"low\", \"low\", \"low\", \"high…\n$ TypeControlGroup     &lt;chr&gt; \"WLC\", \"WLC\", \"WLC\", \"no intervention\", \"informat…\n$ InterventionDuration &lt;chr&gt; \"short\", \"short\", \"short\", \"short\", \"short\", \"sho…\n$ InterventionType     &lt;chr&gt; \"mindfulness\", \"mindfulness\", \"ACT\", \"mindfulness…\n$ ModeOfDelivery       &lt;chr&gt; \"group\", \"online\", \"group\", \"group\", \"online\", \"g…\n\n\n\n# Define vector with effects on anxiety (Hedges g)\nAnxiety &lt;- c(0.224,0.389,0.913,0.255,0.615,-0.021,0.201, \n             0.665,0.373,1.118,0.158,0.252,0.142,NA, \n             0.410,1.139,-0.002,1.084)\n\n# Standard error of anxiety effects\nAnxiety_SE &lt;- c(0.193,0.194,0.314,0.165,0.270,0.233,0.159,\n                0.298,0.153,0.388,0.206,0.256,0.256,NA,\n                0.431,0.242,0.274,0.250)\n\n# Covariance between stress and anxiety outcomes\nCovariance &lt;- c(0.023,0.028,0.065,0.008,0.018,0.032,0.026, \n                0.046,0.020,0.063,0.017,0.043,0.037,NA, \n                0.079,0.046,0.040,0.041)\n\n\nThirdWaveMV &lt;- data.frame(Author = ThirdWave$Author,\n                          Stress = ThirdWave$TE,\n                          Stress_var = ThirdWave$seTE^2,\n                          Anxiety = Anxiety,\n                          Anxiety_var = Anxiety_SE^2,\n                          Covariance = Covariance)\n\nformat(head(ThirdWaveMV), digits = 2)\n\n           Author Stress Stress_var Anxiety Anxiety_var Covariance\n1     Call et al.   0.71      0.068   0.224       0.037      0.023\n2 Cavanagh et al.   0.35      0.039   0.389       0.038      0.028\n3   DanitzOrsillo   1.79      0.119   0.913       0.099      0.065\n4  de Vibe et al.   0.18      0.014   0.255       0.027      0.008\n5  Frazier et al.   0.42      0.021   0.615       0.073      0.018\n6  Frogeli et al.   0.63      0.038  -0.021       0.054      0.032\n\n\n\n# We use the square root of the variance since SE = sqrt(var)\ncov.est &lt;- with(ThirdWaveMV, \n                sqrt(Stress_var) * sqrt(Anxiety_var) * 0.6)\n\n\n\n11.2.2 Specifying the Model\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV)\n\n\n#summary(m.mv)\n\n#rerun(m.mv)\n\n\ntau.coefs &lt;- coef(m.mv, select = \"random\")\n\n\n# Create matrix\ntc.mat &lt;- vec2symMat(tau.coefs)\n\n# Label rows and columns\ndimnames(tc.mat)[[1]] &lt;- dimnames(tc.mat)[[2]] &lt;- c(\"Stress\", \n                                                    \"Anxiety\")\n\ntc.mat\n\n            Stress    Anxiety\nStress  0.07331199 0.02894342\nAnxiety 0.02894342 0.05753271\n\n\n\ncov2cor(tc.mat)\n\n           Stress   Anxiety\nStress  1.0000000 0.4456613\nAnxiety 0.4456613 1.0000000\n\n\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             intervals.type = \"LB\")\n\n\nm.mv &lt;- meta(y = cbind(Stress, Anxiety), \n             v = cbind(Stress_var, Covariance, Anxiety_var),\n             data = ThirdWaveMV,\n             RE.constraints = matrix(0, nrow=2, ncol=2))\n\n\n\n11.2.3 Visualizing the results\n\nplot(m.mv, \n     axis.labels = c(\"Perceived Stress\", \"Anxiety\"), \n     randeff.ellipse.col = \"#014d64\",\n     univariate.arrows.col = \"gray40\",\n     univariate.arrows.lwd = 9,\n     univariate.polygon.col = \"gray40\",\n     estimate.ellipse.col = \"gray40\",\n     estimate.col = \"firebrick\")"
  },
  {
    "objectID": "12-network_meta-analysis.html#theorie",
    "href": "12-network_meta-analysis.html#theorie",
    "title": "12  Network Meta-Analysis",
    "section": "12.1 Theorie",
    "text": "12.1 Theorie\nNetwerkmeta-analyse is een nuttig hulpmiddel om de relatieve effectiviteit van verschillende behandelingen of interventies gezamenlijk in te schatten. Netwerk meta-analyse staat ook bekend als mixed-treatment comparison meta-analyse. Dit komt omdat het meerdere directe en indirecte behandelingsvergelijkingen integreert in één model, dat kan worden geformaliseerd als een “netwerk” van vergelijkingen. Netwerk meta-analyse is een “hot” onderzoeksonderwerp. In de afgelopen tien jaar is het steeds meer opgepikt door toegepaste onderzoekers in de biomedische sector en andere disciplines. Deze methode gaat echter ook gepaard met extra uitdagingen en valkuilen, vooral met betrekking tot heterogeniteit en zogenaamde netwerkinconsistentie.\nNetwerk meta-analyse heeft enkele voordelen: - Het stelt ons in staat om alle beschikbare informatie van een reeks gerelateerde onderzoeken samen te voegen in één analyse. Bedenk hoe we in conventionele meta-analyses gewoonlijk omgaan met onderzoeken waarin verschillende behandelingen worden vergeleken met, laten we zeggen, een placebo. We zouden dan elke vergelijking moeten samenvoegen (bijv. behandeling A vergeleken met placebo, behandeling B vergeleken met placebo, behandeling A vergeleken met behandeling B, enz) in een aparte meta-analyse.\n\nNetwerkmeta-analyse kan indirect bewijs in een netwerk opnemen, wat niet mogelijk is in conventionele meta-analyse. In paarsgewijze meta-analyses kunnen we alleen direct bewijs samenvoegen van vergelijkingen die daadwerkelijk in een trial waren opgenomen.\nAls aan alle aannames is voldaan en als de resultaten voldoende overtuigend zijn, kunnen we uit netwerkmeta-analyses afleiden welk type behandeling de voorkeur verdient voor de onderzochte doelpopulatie.\n\nOm de behandelingseffecten te schatten, combineert netwerk meta-analyse dus zowel direct (d.w.z. waargenomen) als indirect bewijs. Dit is echter gebaseerd op de aanname van transitiviteit. Er is sprake van transitiviteit als we direct bewijs van twee vergelijkingen kunnen combineren om daaruit geldig indirect bewijs af te leiden over een derde vergelijking (van bv vergelijkingen \\(A-B\\) en \\(C-B\\) om indirect bewijs te leveren over een gerelateerde vergelijking als bv \\(A-C\\)). De statistische manifestatie van transitiviteit is consistentie, het tegenovergestelde daarvan is inconsistentie. Van consistentie is sprake wanneer het werkelijke effect van een vergelijking op basis van direct bewijs overeenkomt met het effect op basis van indirect bewijs, inconsistentie ontstaat wanneer dat niet het geval is.\nEr zijn verschillende netwerk meta-analyse modellen beschikbaar. Sommige methoden, zoals nodesplitting of net heat plots, kunnen worden gebruikt om inconsistenties in ons netwerk te identificeren. Als er inconsistenties worden gevonden, bedreigt dit de geldigheid van onze resultaten als geheel. In dergelijke gevallen moet het hele netwerk worden gecontroleerd op kenmerken die systematische verschillen tussen studies/ontwerpen kunnen hebben veroorzaakt. Netwerk meta-analyse kan met een frequentistische of een Bayesiaanse aanpak worden uitgevoerd. In de praktijk heeft elk van deze methoden zijn eigen sterke punten, maar de algemene resultaten lijken meestal erg op elkaar.\nIn netwerkmeta-analyses op basis van een Bayesiaans hiërarchisch model kunnen we ook studiecovariaten toevoegen die verschillen in effectgrootte voorspellen. Dit resulteert in een netwerk meta-regressiemodel.\nIndices zoals de SUCRA of P-score kunnen worden gebruikt om te onderzoeken welk type behandeling het meest effectief is in ons netwerk. Het is echter ook belangrijk om onzekerheid te integreren in ons besluitvormingsproces.\nWaarschijnlijkheidsintervallen van verschillende behandelingen overlappen elkaar vaak, waardoor het minder duidelijk is of één vorm echt superieur is aan alle andere."
  },
  {
    "objectID": "12-network_meta-analysis.html#praktijk",
    "href": "12-network_meta-analysis.html#praktijk",
    "title": "12  Network Meta-Analysis",
    "section": "12.2 Praktijk",
    "text": "12.2 Praktijk\nHet {gemtc} pakket is afhankelijk van {rjags}, dat kan worden gebruikt voor de Gibbs sampling procedure. Daarvoor moet je wel JAGS hebben geinstalleerd op je computer. Daarna kun je {rjags} binnenhalen.\n\nlibrary(gemtc)\n\nLoading required package: coda\n\nlibrary(rjags)\n\nLinked to JAGS 4.3.0\n\n\nLoaded modules: basemod,bugs\n\n\n\n12.2.1 Data preparation\nDe TherapyFormatsGeMTC dataset is eigenlijk een list met twee elementen, waarvan er één data heet. Dit element is het dataframe dat we nodig hebben om het model te draaien. Laten we er eens naar kijken.\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\n\n\nAttaching package: 'dmetar'\n\n\nThe following object is masked from 'package:gemtc':\n\n    sucra\n\ndata(TherapyFormatsGeMTC)\n\nhead(TherapyFormatsGeMTC$data)\n\n         study   diff std.err treatment\n1 Ausbun, 1997  0.092   0.195       ind\n2 Ausbun, 1997     NA      NA       grp\n3 Crable, 1986 -0.675   0.350       ind\n4 Crable, 1986     NA      NA       grp\n5 Thiede, 2011 -0.107   0.198       ind\n6 Thiede, 2011     NA      NA       grp\n\n\n\nstudy: de studie waaruit de data afkomstig is;\ndiff: de effectsize (SMD) van de vergelijking;\n\nstd.err: de standaardfout van de effectsize;\n\ntreatment: label voor soort behandeling.\n\n\n\n12.2.2 Netwerk visualisatie\nNu we de data hebben, zetten we de mtc.network functie aan. Het optionele treatments argument kan gebruikt worden om {gemtc} te voorzien van de werkelijke namen van alle behandelingen die in het netwerk zijn opgenomen. Deze informatie moet worden klaargezet in een dataframe met een id- en een description-kolom. We hebben zo’n dataframe gemaakt en opgeslagen als treat.codes in TherapyFormatsGeMTC:\n\nTherapyFormatsGeMTC$treat.codes\n\n   id        description\n1 ind         Individual\n2 grp              Group\n3 gsh   Guided Self-Help\n4 tel          Telephone\n5 wlc           Waitlist\n6 cau      Care As Usual\n7 ush Unguided Self-Help\n\n\nWe gebruiken dit dataframe en onze effectsize-gegevens in TherapyFormatsGeMTC om ons mtc.network-object te maken. We slaan het op onder de naam network.\n\nnetwork &lt;- mtc.network(data.re  = TherapyFormatsGeMTC$data,\n                       treatments = TherapyFormatsGeMTC$treat.codes)\n\nDoor het resulterende object in de summary-functie te stoppen, krijgen we al wat interessante informatie over ons netwerk.\n\nsummary(network)\n\n$Description\n[1] \"MTC dataset: Network\"\n\n$`Studies per treatment`\nind grp gsh tel wlc cau ush \n 62  52  57  11  83  74  26 \n\n$`Number of n-arm studies`\n2-arm 3-arm \n  181     1 \n\n$`Studies per treatment comparison`\n    t1  t2 nr\n1  ind tel  4\n2  ind wlc 18\n3  grp ind  7\n4  grp gsh  5\n5  grp wlc 18\n6  grp ush  1\n7  gsh ind  4\n8  gsh wlc 36\n9  gsh ush  5\n10 tel wlc  1\n11 cau ind 30\n12 cau grp 21\n13 cau gsh  8\n14 cau tel  6\n15 cau ush  9\n16 ush wlc 11\n\n\nWe kunnen nu ook de plot-functie gebruiken om een netwerkplot te genereren. De dikte van de randen komt overeen met het aantal studies dat we hebben opgenomen voor die vergelijking.\n\nplot(network, \n     use.description = TRUE) # Use full treatment names\n\n\n\n\nMet het {igraph} pakket kunnen we de netwerkplot ook aanpassen. Kijk voor meer informatie over de mogelijke aanpassingen naar de documentatie van igraph.\n\nlibrary(igraph)\n\n\nAttaching package: 'igraph'\n\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\n\nThe following object is masked from 'package:base':\n\n    union\n\nset.seed(12345) # set seed for reproducibility\n\nplot(network, \n     use.description = TRUE,            # Use full treatment names\n     vertex.color = \"white\",            # node color\n     vertex.label.color = \"gray10\",     # treatment label color\n     vertex.shape = \"sphere\",           # shape of the node\n     vertex.label.family = \"Helvetica\", # label font\n     vertex.size = 20,                  # size of the node\n     vertex.label.dist = 2,             # distance label-node center\n     vertex.label.cex = 1.5,            # node label size\n     edge.curved = 0.2,                 # edge curvature\n     layout = layout.fruchterman.reingold)\n\n\n\n\n\n\n12.2.3 Model samenstelling\nNu we ons netwerk hebben, kunnen we een model samenstellen. We gebruiken de mtc.model-functie om een model te maken. We geven ons netwerk, de likelihood, link, linearModel en het aantal chains mee.\n\n# We give our compiled model the name `model`.\nmodel &lt;- mtc.model(network,\n                   likelihood = \"normal\",\n                   link = \"identity\",\n                   linearModel = \"random\",\n                   n.chain = 4)\n\n\n\n12.2.4 MCMC sampling en convergentie\nModellen kunnen we op verschillende manieren specificeren. Laten we twee modellen definieren.\n\nmcmc1 &lt;- mtc.run(model, n.adapt = 50, n.iter = 1000, thin = 10)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 182\n   Unobserved stochastic nodes: 190\n   Total graph size: 2606\n\nInitializing model\n\n\nWarning in rjags::jags.model(file.model, data = syntax[[\"data\"]], inits =\nsyntax[[\"inits\"]], : Adaptation incomplete\n\n\nNOTE: Stopping adaptation\n\nmcmc2 &lt;- mtc.run(model, n.adapt = 5000, n.iter = 1e5, thin = 10)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 182\n   Unobserved stochastic nodes: 190\n   Total graph size: 2606\n\nInitializing model\n\n\nOm te zien of de modellen zijn geconvergeerd, plotten we ze. Op basis van trace en met name densityplots zie je dat het tweede model er betrouwbaarder uitziet.\n\npar(mar = c(1, 1, 1, 1))\nplot(mcmc1)\n\n\n\n\n\n\nplot(mcmc2)\n\n\n\n\n\n\n\nVoor diagnostiek kun je ook nog Gelman-plots draaien. Waarden moeten dicht bij 1 liggen. Dat is bij beiden het geval ook al toont het tweede model een betere convergentie.\n\npar(mar = c(1, 1, 1, 1))\ngelman.plot(mcmc1)\n\n\n\ngelman.plot(mcmc2)\n\n\n\n\nDe waarde kun je ook direct opvragen.\n\ngelman.diag(mcmc1)$mpsrf\n\n[1] 1.035278\n\n\n\ngelman.diag(mcmc2)$mpsrf\n\n[1] 1.000577\n\n\n\n\n12.2.5 Netwerk meta-regressie\nEen groot voordeel van het {gemtc} pakket is dat je er een netwerk meta-regressie mee kan uitvoeren. Stel dat we willen evalueren of het risico op bias van een studie invloed heeft op de effecten in onze netwerkmeta-analyse. Het zou bijvoorbeeld kunnen dat studies met een hoog biasrisico over het algemeen hogere effecten rapporteren in vergelijking met de controlegroep of alternatieve behandelingen. Door het biasrisico als voorspeller op te nemen in ons model, kunnen we controleren op een dergelijke associatie en de invloed ervan op onze resultaten beoordelen.\n\nTherapyFormatsGeMTC$study.info\n\n                       study rob\n1             Campbell, 2000   1\n2             Reynolds, 1989   1\n3            Carpenter, 1994   0\n4             Shrednik, 2000   1\n5               Lesley, 1999   1\n6                Wyatt, 2003   0\n7                Lemon, 2005   1\n8                James, 2012   0\n9              Graesch, 2000   0\n10               Lange, 1993   1\n11         Marinkovich, 2003   1\n12              Wuertz, 2016   1\n13              Hughey, 2012   1\n14               Dobbs, 2000   1\n15               Quick, 2006   1\n16             Harbert, 1999   1\n17              Nelson, 1987   1\n18          Watkins Jr, 2004   1\n19              Ristau, 1992   1\n20            Schlegel, 1989   1\n21            Wierenga, 2004   1\n22               Laird, 2008   1\n23               Riley, 2002   1\n24            Germuska, 1996   0\n25            Schulker, 2009   1\n26             Barrett, 2005   1\n27                Neil, 2015   1\n28             Congour, 1996   1\n29               Hurla, 1985   1\n30            Hanrahan, 1999   1\n31            Koslosky, 1991   1\n32             Runnels, 2004   1\n33               Orman, 2012   0\n34              Dewitt, 1995   1\n35                Fair, 2003   0\n36            Schlaver, 2004   1\n37                King, 1990   1\n38              Snider, 1998   1\n39               Craft, 2014   1\n40           Ceurvorst, 2011   1\n41             Roberts, 1996   1\n42             Carrell, 2008   0\n43         Muhlenbruck, 1998   1\n44              Kramer, 2007   1\n45              Barker, 1997   0\n46             Johnson, 1989   1\n47               Shorb, 1998   0\n48             Scholer, 2017   1\n49             Maurath, 1994   0\n50               Leach, 2014   1\n51             Roberts, 1997   1\n52          De Venecia, 2011   1\n53                Shea, 2011   1\n54           Gilleland, 1989   1\n55              Murray, 1996   1\n56             Menzies, 2003   0\n57            Chambers, 2010   1\n58              Mickey, 1989   1\n59               Hiatt, 1985   1\n60             Breiman, 2001   1\n61              Parker, 2002   1\n62            Erickson, 1998   1\n63              Ancmon, 2001   0\n64            Fladland, 1997   1\n65               Crane, 1984   1\n66         Christenson, 2018   1\n67               Plewe, 1991   1\n68           Fergerson, 2014   1\n69             Frenzel, 2006   0\n70              Walker, 1990   1\n71              Crable, 1986   1\n72               Gilly, 2014   1\n73              Austin, 1988   1\n74            Whitaker, 2017   1\n75             Breiman, 2001   1\n76               Brown, 1985   1\n77                Dahl, 2002   0\n78               Clear, 1989   1\n79          Oberholser, 2008   1\n80        Debenedictis, 1993   0\n81              Martin, 2017   1\n82              Hassan, 2011   1\n83       Knickerbocker, 1987   1\n84                Cook, 2013   0\n85             Ciccone, 1997   0\n86          Summerhays, 1987   0\n87               Silva, 1986   1\n88            Thompson, 2003   0\n89               Pauly, 2003   0\n90            Schwartz, 2012   0\n91             Englund, 2017   0\n92              Horton, 1985   0\n93               Scott, 1993   0\n94              Staley, 1992   1\n95               Allen, 2003   0\n96          Vahlenkamp, 2006   1\n97             Blevins, 2003   0\n98             Huebner, 1997   0\n99             Mcmanus, 1987   0\n100            Fotenos, 1994   0\n101            Delaney, 1995   0\n102                Fay, 2002   0\n103                Mai, 2003   0\n104             Nelson, 2006   0\n105              Reeve, 2013   0\n106          Eisenberg, 1995   0\n107            Woodard, 2013   0\n108            Roberts, 2017   0\n109            Jeffers, 1996   0\n110        Rusciolelli, 2000   0\n111             Miller, 1989   0\n112              Ayers, 2008   0\n113             Wagner, 1994   0\n114             Nguyen, 1996   1\n115             Weimer, 1999   0\n116              Isles, 2003   0\n117              Ralph, 1989   0\n118              Brown, 2017   0\n119             Burges, 1993   0\n120           Williams, 1989   0\n121             Pylkka, 2008   0\n122            Kilgore, 2003   1\n123           Tenbarge, 2000   1\n124             Carvey, 2008   0\n125            Mcmahon, 1998   0\n126            Metzger, 1988   0\n127            Warwick, 1986   0\n128              Lopez, 2011   0\n129             Burgan, 2012   0\n130             Gruber, 2013   0\n131              Meraz, 2014   0\n132                Ono, 1985   0\n133             Gleave, 2004   0\n134            Whiting, 1990   0\n135            Ebberts, 1992   0\n136           Thompson, 1998   0\n137              Jones, 2013   0\n138              Kurth, 1992   0\n139            Maranto, 1997   0\n140           Sheppard, 1994   0\n141               Belk, 1986   0\n142             Harder, 2005   0\n143            Hopkins, 2003   0\n144           Gilstrap, 2015   1\n145 Quinonez Dominguez, 1993   1\n146       Hetherington, 2003   0\n147           Bengston, 2004   0\n148                Joy, 2002   0\n149           Robinson, 2015   0\n150           Amsberry, 2010   0\n151             Thiede, 2011   1\n152            Bonertz, 2015   1\n153            Sheehan, 2013   0\n154              White, 2006   0\n155             Lucero, 2001   1\n156            Edwards, 2010   0\n157            Godinez, 2005   0\n158               Hall, 1997   0\n159          Underwood, 2008   0\n160          Ledbetter, 1984   0\n161              Hayko, 1999   0\n162        Chamberlain, 2011   0\n163           Fourroux, 1999   0\n164            Leonard, 2010   0\n165              Narum, 1986   1\n166  Villalobos-Valles, 2006   0\n167               Duba, 1990   0\n168             Ausbun, 1997   0\n169             Durgan, 1998   0\n170              Aaron, 2004   0\n171              Heath, 1998   0\n172             Vaclav, 1984   0\n173            Rodgers, 1993   0\n174             Watson, 1997   0\n175           Tamburri, 2001   0\n176       Homrighausen, 2002   0\n177          Buchholtz, 2010   0\n178              Cowan, 2010   1\n179               Bond, 1988   0\n180              Edgar, 2015   0\n181           Sherratt, 2000   0\n182 Santistevan-Gettel, 2012   0\n183             Graham, 1986   0\n\n\nDe dataset bevat twee kolommen: study, de naam van de studie die is opgenomen in ons netwerk en rob, het biasrisico (o voor laag en 1 voor hoog biasrisico).\nMet dataframe study.info kunnen we nu een meta-regressienetwerk maken met mtc.network.\n\nnetwork.mr &lt;- mtc.network(data.re = TherapyFormatsGeMTC$data,\n                          studies = TherapyFormatsGeMTC$study.info,\n                          treatments = TherapyFormatsGeMTC$treat.codes)\n\nNu moeten we de regressor definiëren die we willen opnemen in ons netwerkmeta-analysemodel. Dit kan worden gedaan door een listobject met drie elementen te genereren:\n\ncoëfficiënt: We stellen dit element in op “gedeeld” omdat we één gedeelde coëfficiënt willen schatten voor het effect van (hoog) biasrisico over alle behandelingen die zijn opgenomen in onze netwerkmeta-analyse.\nvariabele: Dit specificeert de naam van de variabele die we willen gebruiken als predictor (hier: rob).\ncontrole: We moeten ook de behandeling specificeren die we als referentiegroep willen gebruiken. In ons voorbeeld gebruiken we cau (care as usual).\n\n\nregressor &lt;- list(coefficient = \"shared\",\n                  variable = \"rob\",\n                  control = \"cau\")\n\nNu moeten we het model definiëren. We voorzien de functie mtc.model van het netwerk dat we zojuist hebben gegenereerd, stellen het type van ons model in op regression en voorzien de functie van het regressorobject dat we zojuist hebben gegenereerd. We slaan de uitvoer op onder de naam model.mr.\n\nmodel.mr &lt;- mtc.model(network.mr,\n                      likelihood = \"normal\",\n                      link = \"identity\",\n                      type = \"regression\",\n                      regressor = regressor)\n\nNa deze stap kunnen we het model uitvoeren met de functie mtc.run. We gebruiken dezelfde specificaties als we eerder hebben gebruikt voor het passen van het mcmc2-model. De resultaten worden opgeslagen als mcmc3.\n\nmcmc3 &lt;- mtc.run(model.mr,\n                 n.adapt = 5000,\n                 n.iter = 1e5,\n                 thin = 10)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 182\n   Unobserved stochastic nodes: 191\n   Total graph size: 2980\n\nInitializing model\n\n\nNu kunnen we het analyseren met de summary-functie.\n\nsummary(mcmc3)\n\n\nResults on the Mean Difference scale\n\nIterations = 5010:105000\nThinning interval = 10 \nNumber of chains = 4 \nSample size per chain = 10000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n              Mean      SD  Naive SE Time-series SE\nd.ind.cau  0.69902 0.07980 0.0003990      0.0004198\nd.ind.grp  0.19288 0.10044 0.0005022      0.0005439\nd.ind.gsh  0.16121 0.10467 0.0005233      0.0005576\nd.ind.tel  0.02273 0.16239 0.0008119      0.0008164\nd.ind.wlc  0.95051 0.09206 0.0004603      0.0004994\nd.wlc.ush -0.45545 0.11540 0.0005770      0.0005744\nsd.d       0.47060 0.03403 0.0001701      0.0001711\nB         -0.33205 0.13003 0.0006502      0.0010424\n\n2. Quantiles for each variable:\n\n               2.5%      25%      50%     75%   97.5%\nd.ind.cau  0.542709  0.64513  0.69872  0.7525  0.8559\nd.ind.grp -0.004622  0.12585  0.19281  0.2599  0.3901\nd.ind.gsh -0.043723  0.09062  0.16180  0.2320  0.3650\nd.ind.tel -0.299458 -0.08486  0.02381  0.1314  0.3407\nd.ind.wlc  0.770141  0.88924  0.95011  1.0118  1.1333\nd.wlc.ush -0.680003 -0.53358 -0.45566 -0.3774 -0.2287\nsd.d       0.407829  0.44685  0.46930  0.4930  0.5408\nB         -0.586304 -0.41980 -0.33141 -0.2448 -0.0775\n\n-- Model fit (residual deviance):\n\n     Dbar        pD       DIC \n185.73014  74.50512 260.23526 \n\n183 data points, ratio 1.015, I^2 = 2%\n\n-- Regression settings:\n\nRegression on \"rob\", shared coefficients, \"cau\" as control\nInput standardized: x' = (rob - 0.4340659) / 1\nEstimates at the centering value: rob = 0.4340659\n\n\nDe resultaten voor onze predictor worden gerapporteerd naast \\(B\\). Omdat onze voorspeller een dummycode heeft, vertegenwoordigt de waarde van \\(B\\) het effect van een onderzoek met een hoog biasrisico. De schatting is \\(b= -0,33\\), en als we kijken naar de tweede tabel (Kwantielen voor elke variabele), zien we dat het 95% geloofwaardigheidsinterval van \\(b\\) varieert van -0,59 tot -0,08. Omdat het interval geen nul bevat, kunnen we concluderen dat het biasrisico inderdaad van invloed is op de resultaten. Als het biasrisico hoog is (rob = 1), kunnen we hier hogere totale effecten voorspellen (omdat negatieve effectgroottes in ons voorbeeld wijzen op “betere” uitkomsten).\nWe kunnen de resultaten verder onderzoeken door het maken van twee forestplot: een met lage bias en een met hoge bias. We gebruiken de functie relative.effect en specificeren covariate waarde 0 en 1.\n\nforest(relative.effect(mcmc3, t1 = \"cau\", covariate = 1),\n       use.description = TRUE, xlim = c(-1.5, 1))\ntitle(\"Hoge Risicobias\")\n\n\n\nforest(relative.effect(mcmc3, t1 = \"cau\", covariate = 0),\n       use.description = TRUE, xlim = c(-1.5, 1))\ntitle(\"Lage Risicobias\")\n\n\n\n\nAls we de forest plots vergelijken, zien we dat er een patroon is. De behandelingseffecten op basis van studies met een hoog biasrisico zijn over het algemeen hoger (d.w.z. negatiever). Dit komt overeen met de schatting van onze predictor \\(b\\) in het gepaste model.\nTot slot kunnen we ook onderzoeken of het netwerkmeta-regressiemodel dat we net hebben gegenereerd beter past bij de gegevens dan het “normale” netwerkmeta-analysemodel van eerder. Om dit te doen, kunnen we de deviance-informatiecriteria (DIC’s) vergelijken, die een equivalent zijn van de AIC- en BIC-waarden in frequentistische statistieken. We kunnen de DIC van zowel mcmc3:\n\nsummary(mcmc3)$DIC\n\n       Dbar          pD         DIC data points \n  185.73014    74.50512   260.23526   183.00000 \n\n\nals mcmc2 opvragen met deze code:\n\nsummary(mcmc2)$DIC\n\n       Dbar          pD         DIC data points \n   185.2144    137.8202    323.0345    183.0000 \n\n\nWe zien in de uitvoer dat de DIC-waarde van ons meta-regressiemodel (\\(DIC = 261,19\\)) lager is dan die van ons vorige model waarin niet werd gecontroleerd voor risico van vertekening (\\(DIC = 323,6\\)). Lagere DIC-waarden duiden op een betere pasvorm. Op basis van deze bevinding kunnen we concluderen dat ons netwerk meta-regressiemodel beter past bij de gegevens dan een model zonder covariaat."
  }
]