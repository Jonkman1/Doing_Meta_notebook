[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notitieboekje dat hoort bij Doing Meta-Analysis with R. A Hands-On Guide",
    "section": "",
    "text": "Voorwoord\nDit is mijn notitieboekje dat hoort bij Doing Meta-Analysis with R dat Mathias Harrer, Pim Cuijpers, Toshi Furukawa, and David Ebert schreven. Dat boek van Harrer en anderen is een open source boek dat je kunt vinden op https://doingmetaanalysis.github.io. Omdat ik de komende maanden een groep studenten begeleid bij het maken van een masterthesis, waarbij ze de techniek van meta-analyse gebruiken, heb ik dit gemaakt om hen goed bij het uitvoeren van hun activiteiten te ondersteunen.\n\n\n\nHet boek"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "01-introductie.html",
    "href": "01-introductie.html",
    "title": "1  Introductie",
    "section": "",
    "text": "Met die grote hoeveelheden onderzoeksresultaten die elke dag worden geproduceerd, is het nog belangrijker geworden om het bewijsmateriaal in zijn geheel te bekijken en het kritisch te beoordelen. Meta-analyse kan hierbij enorm helpen, zolang de beperkingen en vooroordelen ervan worden erkend. Het doel van meta-analyse is om al het beschikbare bewijsmateriaal met betrekking tot een duidelijk gedefinieerd onderzoeksgebied of onderzoeksvraag te combineren, dat samen te vatten en uiteindelijk te interpreteren. Er zijn ten minste drie verschillende manieren waarop bewijs uit meerdere onderzoeken kan worden samengevoegd:\n\nTraditionele/narratieve reviews (geschreven door experts en autoriteiten in het veld zonder duidelijke regels).\n\nSystematische reviews (om bewijs samen te vatten met behulp van duidelijk gedefinieerde en transparante regels).\n\nMeta-analyses (om bewijs te combineren en samen te vatten over alle onderzoeken met behulp van duidelijk gedefinieerde en transparante regels op kwantitatieve wijze).\n\n\nMeta-analyse is niet uitgevonden door één persoon alleen, maar kent vele grondleggers en vaders. De eerste pogingen om de effecten van afzonderlijke, maar vergelijkbare onderzoeken statistisch samen te vatten, dateren van ongeveer 100 jaar geleden. Talloze innovaties hebben de toepasbaarheid, robuustheid en veelzijdigheid van de meta-analytische methoden in de laatste vier decennia vergroot. In die periode is meta-analyse een universeel geaccepteerd onderzoeksinstrument geworden. Er zijn veel valkuilen en het boek leidt ons langs veelvoorkomende valkuilen in de uitvoering van meta-analyse. Hier worden er vier genoemd:\n\n\nHet “Appels en Sinaasappelen” probleem: Je zou kunnen stellen dat meta-analyse appels met peren combineren is. De reikwijdte en specificiteit van een meta-analyse moet daarom gebaseerd zijn op de onderzoeksvraag die beantwoord moet worden, en deze vraag moet van praktisch belang zijn. Variatie tussen studies kan onproblematisch zijn, zelfs inzichtgevend, als die op de juiste manier wordt opgenomen in de doelen en probleemspecificatie van een meta-analyse.\n\nHet “Vuiligheid Erin, Vuiligheid Eruit”-probleem: De kwaliteit van het bewijs dat een meta-analyse oplevert, hangt sterk af van de kwaliteit van de studies die erin worden samengevat. Anders krijg je “vuiligheid erin, vuiligheid eruit”.\n\nHet “Dossierlader”-probleem: Het dossierladerprobleem verwijst naar het probleem dat niet alle relevante onderzoeksresultaten worden gepubliceerd. Negatieve of ‘teleurstellende’ resultaten zijn ondervertegenwoordigd. Daarom moet je kijken naar publicatiebias.\n\nHet “agenda van de onderzoeker”-probleem: Meta-analyse gaat gepaard met veel “vrijheidsgraden van de onderzoeker”, waardoor er veel ruimte overblijft voor beslissingen die soms willekeurig en soms het resultaat van geheime persoonlijke voorkeuren zijn. Een manier om het probleem van de agenda van de onderzoeker te verminderen, is het vooraf registreren en publiceren van een gedetailleerd analyseplan voordat met het verzamelen van gegevens voor een meta-analyse wordt begonnen.\n\n\nBelangrijk is dat de methodologische beslissingen zowel transparant als reproduceerbaar zijn. Hier worden de eerste bouwstenen gepresenteerd. Definieer de onderzoeksvraag: of een goede onderzoeksvraag te definiëren, helpt het om deze eerst te zien als een vorm van probleemspecificatie. Door jezelf stap voor stap deze vragen te stellen, zou het gemakkelijker moeten worden om te definiëren wat je wilt bereiken met je meta-analyse. Gebruik bijvoorbeeld het FINER-raamwerk (Feasible, Interesting, Novel, Ethical, Relevant) of PICO (Population, Intervention, Comparison, Outcome) om je onderzoeksvraag te definiëren.\nKijk verder ook naar in aanmerking komende onderzoeksdesigns, houd rekening met culturele en taalkundige verschillen tussen in aanmerking komende studies, en kijk naar publicatietype en de rol van grijze literatuur. Schrijf deze dingen in inclusie en uitsluitingscriteria. Houd bij dit alles rekening met de PRISMA- () en MARS- ()-richtlijnen. Veel van deze problemen kunnen worden verminderd door een duidelijke onderzoeksvraag en geschiktheidscriteria te definiëren, een analyseplan te schrijven, de meta-analyse vooraf te registreren en de studiezoektocht en gegevensextractie op een systematische en reproduceerbare manier uit te voeren."
  },
  {
    "objectID": "02-discovering_R.html",
    "href": "02-discovering_R.html",
    "title": "2  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "03-effect_sizes.html",
    "href": "03-effect_sizes.html",
    "title": "3  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "04-pooling_effect_sizes.html",
    "href": "04-pooling_effect_sizes.html",
    "title": "4  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "05-between_study_heterogeneity.html",
    "href": "05-between_study_heterogeneity.html",
    "title": "5  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "06-forest_plots.html",
    "href": "06-forest_plots.html",
    "title": "6  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "07-subgroup_analyses.html",
    "href": "07-subgroup_analyses.html",
    "title": "7  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "08-meta_regression.html",
    "href": "08-meta_regression.html",
    "title": "8  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "09-publication_bias.html",
    "href": "09-publication_bias.html",
    "title": "9  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "10-multilevel_meta-analysis.html",
    "href": "10-multilevel_meta-analysis.html",
    "title": "10  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "11-seq_meta-analysis.html",
    "href": "11-seq_meta-analysis.html",
    "title": "11  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "12-network_meta-analysis.html",
    "href": "12-network_meta-analysis.html",
    "title": "12  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "13-bayesian_meta-analysis.html",
    "href": "13-bayesian_meta-analysis.html",
    "title": "13  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "14-power_analysis.html",
    "href": "14-power_analysis.html",
    "title": "14  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "15-risk_bias_plots.html",
    "href": "15-risk_bias_plots.html",
    "title": "15  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "16-reporting_reproducibility.html",
    "href": "16-reporting_reproducibility.html",
    "title": "16  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "17-es_calculation_conversion.html",
    "href": "17-es_calculation_conversion.html",
    "title": "17  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  }
]