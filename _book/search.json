[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notitieboekje dat hoort bij Doing Meta-Analysis with R. A Hands-On Guide",
    "section": "",
    "text": "Voorwoord\nDit is mijn notitieboekje dat hoort bij Doing Meta-Analysis with R dat Mathias Harrer, Pim Cuijpers, Toshi Furukawa, and David Ebert schreven. Dat boek van Harrer en anderen is een open source boek dat je kunt vinden op https://doingmetaanalysis.github.io. Omdat ik de komende maanden een groep studenten begeleid bij het maken van een masterthesis, waarbij ze de techniek van meta-analyse gebruiken, heb ik dit gemaakt om hen goed bij het uitvoeren van hun activiteiten te ondersteunen.\n\n\n\nHet boek"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "01-introductie.html",
    "href": "01-introductie.html",
    "title": "1  Introductie",
    "section": "",
    "text": "Met die grote hoeveelheden onderzoeksresultaten die elke dag worden geproduceerd, is het nog belangrijker geworden om het bewijsmateriaal in zijn geheel te bekijken en het kritisch te beoordelen. Meta-analyse kan hierbij enorm helpen, zolang de beperkingen en vooroordelen ervan worden erkend. Het doel van meta-analyse is om al het beschikbare bewijsmateriaal met betrekking tot een duidelijk gedefinieerd onderzoeksgebied of onderzoeksvraag te combineren, dat samen te vatten en uiteindelijk te interpreteren. Er zijn ten minste drie verschillende manieren waarop bewijs uit meerdere onderzoeken kan worden samengevoegd:\n\nTraditionele/narratieve reviews (geschreven door experts en autoriteiten in het veld zonder duidelijke regels).\n\nSystematische reviews (om bewijs samen te vatten met behulp van duidelijk gedefinieerde en transparante regels).\n\nMeta-analyses (om bewijs te combineren en samen te vatten over alle onderzoeken met behulp van duidelijk gedefinieerde en transparante regels op kwantitatieve wijze).\n\n\nMeta-analyse is niet uitgevonden door één persoon alleen, maar kent vele grondleggers en vaders. De eerste pogingen om de effecten van afzonderlijke, maar vergelijkbare onderzoeken statistisch samen te vatten, dateren van ongeveer 100 jaar geleden. Talloze innovaties hebben de toepasbaarheid, robuustheid en veelzijdigheid van de meta-analytische methoden in de laatste vier decennia vergroot. In die periode is meta-analyse een universeel geaccepteerd onderzoeksinstrument geworden. Er zijn veel valkuilen en het boek leidt ons langs veelvoorkomende valkuilen in de uitvoering van meta-analyse. Hier worden er vier genoemd:\n\n\nHet “Appels en Sinaasappelen” probleem: Je zou kunnen stellen dat meta-analyse appels met peren combineren is. De reikwijdte en specificiteit van een meta-analyse moet daarom gebaseerd zijn op de onderzoeksvraag die beantwoord moet worden, en deze vraag moet van praktisch belang zijn. Variatie tussen studies kan onproblematisch zijn, zelfs inzichtgevend, als die op de juiste manier wordt opgenomen in de doelen en probleemspecificatie van een meta-analyse.\n\nHet “Vuiligheid Erin, Vuiligheid Eruit”-probleem: De kwaliteit van het bewijs dat een meta-analyse oplevert, hangt sterk af van de kwaliteit van de studies die erin worden samengevat. Anders krijg je “vuiligheid erin, vuiligheid eruit”.\n\nHet “Dossierlader”-probleem: Het dossierladerprobleem verwijst naar het probleem dat niet alle relevante onderzoeksresultaten worden gepubliceerd. Negatieve of ‘teleurstellende’ resultaten zijn ondervertegenwoordigd. Daarom moet je kijken naar publicatiebias.\n\nHet “agenda van de onderzoeker”-probleem: Meta-analyse gaat gepaard met veel “vrijheidsgraden van de onderzoeker”, waardoor er veel ruimte overblijft voor beslissingen die soms willekeurig en soms het resultaat van geheime persoonlijke voorkeuren zijn. Een manier om het probleem van de agenda van de onderzoeker te verminderen, is het vooraf registreren en publiceren van een gedetailleerd analyseplan voordat met het verzamelen van gegevens voor een meta-analyse wordt begonnen.\n\n\nBelangrijk is dat de methodologische beslissingen zowel transparant als reproduceerbaar zijn. Hier worden de eerste bouwstenen gepresenteerd. Definieer de onderzoeksvraag: of een goede onderzoeksvraag te definiëren, helpt het om deze eerst te zien als een vorm van probleemspecificatie. Door jezelf stap voor stap deze vragen te stellen, zou het gemakkelijker moeten worden om te definiëren wat je wilt bereiken met je meta-analyse. Gebruik bijvoorbeeld het FINER-raamwerk (Feasible, Interesting, Novel, Ethical, Relevant) of PICO (Population, Intervention, Comparison, Outcome) om je onderzoeksvraag te definiëren.\nKijk verder ook naar in aanmerking komende onderzoeksdesigns, houd rekening met culturele en taalkundige verschillen tussen in aanmerking komende studies, en kijk naar publicatietype en de rol van grijze literatuur. Schrijf deze dingen in inclusie en uitsluitingscriteria. Houd bij dit alles rekening met de PRISMA- () en MARS- ()-richtlijnen. Veel van deze problemen kunnen worden verminderd door een duidelijke onderzoeksvraag en geschiktheidscriteria te definiëren, een analyseplan te schrijven, de meta-analyse vooraf te registreren en de studiezoektocht en gegevensextractie op een systematische en reproduceerbare manier uit te voeren."
  },
  {
    "objectID": "02-discovering_R.html",
    "href": "02-discovering_R.html",
    "title": "2  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "03-effect_sizes.html",
    "href": "03-effect_sizes.html",
    "title": "3  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "04-pooling_effect_sizes.html",
    "href": "04-pooling_effect_sizes.html",
    "title": "4  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "05-between_study_heterogeneity.html",
    "href": "05-between_study_heterogeneity.html",
    "title": "5  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "06-forest_plots.html",
    "href": "06-forest_plots.html",
    "title": "6  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "07-subgroup_analyses.html",
    "href": "07-subgroup_analyses.html",
    "title": "7  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "08-meta_regression.html",
    "href": "08-meta_regression.html",
    "title": "8  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "09-publication_bias.html",
    "href": "09-publication_bias.html",
    "title": "9  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "10-multilevel_meta-analysis.html",
    "href": "10-multilevel_meta-analysis.html",
    "title": "10  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "11-seq_meta-analysis.html",
    "href": "11-seq_meta-analysis.html",
    "title": "11  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "12-network_meta-analysis.html",
    "href": "12-network_meta-analysis.html",
    "title": "12  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "13-bayesian_meta-analysis.html",
    "href": "13-bayesian_meta-analysis.html",
    "title": "13  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "14-power_analysis.html",
    "href": "14-power_analysis.html",
    "title": "14  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "15-risk_bias_plots.html",
    "href": "15-risk_bias_plots.html",
    "title": "15  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "16-reporting_reproducibility.html",
    "href": "16-reporting_reproducibility.html",
    "title": "16  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "17-es_calculation_conversion.html",
    "href": "17-es_calculation_conversion.html",
    "title": "17  Introductie",
    "section": "",
    "text": "With unprecedented amounts of research findings produced each day, it is even more important to view and critically appraise bodies of evidence in their entirety. Meta-analysis can be enormously helpful in achieving this, as long as we acknowledge its own limitations and biases.\nThe aim of meta-analysis is to combine, summarize and interpret all available evidence pertaining to a clearly defined research field or research question. However, it is only one method to do this. There are at least three distinct ways through which evidence from multiple studies can be synthesized\n- Traditional/narrative reviews (written by experts and authorities in the field without clear rules).\n- Systematic reviews (to summarize evidence using clearly defined and transparent rules).\n- Meta-analyses (to combine and summarize evidence across all studies using clearly defined and transparent rules in quantitative way).\nMeta-analysis was not invented by one person alone, but by many founding mothers and fathers. The first attempts to statistically summarize the effects of separate, but similar studies date back around 100 years. Countless innovations have helped to increase the applicability, robustness and versatility of meta-analytic methods in the last four decades. In the last decades, meta-analysis has become a universally accepted research tool.\nThere are many pitfalls and the book leads us through a quick tour of common meta-analysis pitfalls:\n\nThe “Apples and Oranges” Problem: One may argue that meta-analysis means combining apples with oranges. The scope and specificity of a meta-analysis should therefore be based on the research question it wants to answer, and this question should be of practical relevance. Variation between studies can often be unproblematic, and even insightful if it is correctly incorporated into the aims and problem specification of a meta-analysis.\nThe “Garbage In, Garbage Out” Problem: The quality of evidence produced by a meta-analysis heavily depends on the quality of the studies it summarizes. Otherwise you get “garbage in, garbage out”.\nThe “File Drawer” Problem: The file drawer problem refers to the problem that not all relevant research findings are published. Or negatieve or ‘disappointing’ results are underrepresented. You have to look at publication bias\nThe “Researcher Agenda” Problem: Meta-analysis comes with many “researcher degrees of freedom”, leaving much space for decisions which may sometimes be arbitrary, and sometimes the result of undisclosed personal preferences. One way to reduce the researcher agenda problem is pre-registration, and publishing a detailed analysis plan before beginning with the data collection for a meta-analysis.\n\nImportant is that the methodological decisions are both transparent and reproducible. Here the first building blocks are presented. 1. Define the research question: o define a good research question, it helps to first see it as a form of problem specification. Step by step, asking yourself these questions should make it easier to define what you want to achieve with your meta-analysis. Use e.g. FINER framework (Feasible, Interesting, Novel, Ethical, Relevant) or PICO (Population, Intervention, Comparison, Outcome) to define your research question. Look also at eligible research designs, take into account cultural and linguistic range of eligble studies, and look at publication type and the role of grey literature. Write these things in inclusion and exclusion criteria. For all this take into account the PRISMA () and MARS ()-guidelines.\nMany of these problems can be mitigated by defining a clear research question and eligibility criteria, writing an analysis plan, pre-registering the meta-analysis, and conducting the study search and data extraction in a systematic and reproducible way."
  },
  {
    "objectID": "02-discovering_R.html#theory",
    "href": "02-discovering_R.html#theory",
    "title": "2  Discovering R",
    "section": "2.1 Theory",
    "text": "2.1 Theory\nR has become one of the most powerful and frequently used statistical programming languages in the world. Whether you are working in academia or at a company, the things you can do in R will often seem like a superpower to others. But it is a superpower that everyone can learn, provided some time and effort. The book shows how to install R and RStudio (the last one which gives us a user interface which makes it easier to handle our data, packages and output). R is not a computer program with a graphical user interface and pre-defined functionality. It show how it works.\nR is a full programming language to which people all around the world can contribute freely available add-ons, so-called packages. Important packages for working with this book and to do meta-analysis are meta, metafor, dmetar and (for data wrangling) tidyverse. You have to install these on your computer. When installed you have to load them everytime you start your work.\nThe fundamental building blocks of R are functions. Many of these functions can be imported through packages which we can install from the internet. Functions can be used to import, manipulate, transform and save data using R. Examples important for doing meta-analysis in R are given."
  },
  {
    "objectID": "02-discovering_R.html#practice",
    "href": "02-discovering_R.html#practice",
    "title": "2  Discovering R",
    "section": "2.2 Practice",
    "text": "2.2 Practice\nInstall first the packages needed for this book. I had to install an other version of meta to install the package dmetar.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLoad the packages needed for this book.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoading required package: metadat\nLoading required package: numDeriv\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\n\nDownload the example dataset SuicidePrevention.xlx from here and open it.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLet us have a look at the dataset and look at the kind of variables we have.\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nYou can check specfic columns directly\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nAnd look what kind of variable is this:\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLook at the mean of this variable.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nBe sure the variables have the good class, e.g.here numeric. Let us change this for some variables.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwo variables we have to change to factors to analyse them correctly.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn my case the variable age_group is already split in the levels gen and older, see here:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nA logical variable can also be handy, e.g. for the next one:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSometimes it is good to look at specific data from the dataframe. Remember: data.frame[rows, columns]. So look at row 2 becomes\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nIf you want to see information of first column and second row becomes\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nFor selecting parts of the dataframe use c() function. To extract rows 2 and 3 as well as columns 4 and 6 becomes\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRows you select by number, columns you also can select by name,a s in this example.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nYou can also filter a data set based on row values.\nFor example (more examples as given):\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nYou can transform data easy. So, if you want to transform the study of De Vries et al. from 2019 to 2018 you can write it as:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nIf you want to add a new column to your dataframe (e.g mean difference) you can do it as follows:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nOnce we transformed it, we can save it. You can save it as a .rda file\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nor as a .csv file\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\nImportant: Keep your transformation syntax, so you know what you did from original data to the final data."
  },
  {
    "objectID": "03-effect_sizes.html#theory",
    "href": "03-effect_sizes.html#theory",
    "title": "3  Effect Sizes",
    "section": "3.1 Theory",
    "text": "3.1 Theory\nEffect size is defined here as a metric quantifying the relationship between two entities. It captures the direction and magnitude of this relationship. If relationships are expressed as the same effect size, it is possible to compare them.Effect sizes are the building blocks of meta-analyses.\nTo perform a meta-analysis, we need at least an estimate of the effect size and its standard error. They should be comparable, computable, reliable and interpretable. The standard error of an effect size represents how precise the study’s estimate of the effect is. Meta-analysis gives effect sizes with a greater precision a higher weight because they are better estimators of the true effect.\nThere are various effect sizes we can use in meta-analyses. Common ones are “one-variable” relationship measures, such as: - means (summing all individual values deviding by sum of sample size);\n- proportions (number of individuals falling into a specific subgroup deviding by total number of individuals);\n- correlations (expresses teh amount of co-variation between two variables, for example the Pearson Product-Moment Correlation and Point-Biserial Correlation);\n- (standardized) mean differences (difference in means between two independent groups deviding by the pooled standard deviation); - risk ratio (relative risk) as the ratio of two risks; - odds ratio, as the number of cases which fall into a specific subgroup deviding by the number of cases which do not fall into that subgroup. - incidence rate ratios (also called rate ratio), takes into account the person/time-aspects of two groups.\nEffect sizes can also be biased, for example by measurement error and range restriction. There are formulas to correct for some biases, including the small sample bias of standardized mean differences, attenuation due to unreliability, as well as range restriction problems. Other common problems are that studies report the data needed to calculate effect sizes in different formats, as well as the unit-of-analysis problem, which arises when studies contribute more than one effect size."
  },
  {
    "objectID": "03-effect_sizes.html#practice",
    "href": "03-effect_sizes.html#practice",
    "title": "3  Effect Sizes",
    "section": "3.2 Practice",
    "text": "3.2 Practice\nLet us look first at the bewteen-group standardized mean difference (SMD) effect size. It is used when the outcome is continuous and the predictor is categorical. It is the difference in means between two independent groups deviding by the pooled standard deviation. It is also called Cohen’s d.\n\\[SMD_{between} = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p}\\]\nwhere \\(\\bar{X}_1\\) and \\(\\bar{X}_2\\) are the means of the two groups and \\(s_p\\) is the pooled standard deviation. SMD’s are often interpreted as small (0.2), medium (0.5) and large (0.8) effects.\nThere are several functions in R which allow us to calculate SMDbetween/Cohen’s d in one step. Here, we use the esc_mean_sd function, which is part of the esc-package. We have not used this package before, so it is necessary to install it first.\n\n# install.packages(\"esc\")\nlibrary(esc)\n\n# Define the data we need to calculate SMD/d\n# This is just some example data that we made up\ngrp1m &lt;- 50   # mean of group 1\ngrp2m &lt;- 60   # mean of group 2\ngrp1sd &lt;- 10  # sd of group 1\ngrp2sd &lt;- 10  # sd of group 2\ngrp1n &lt;- 100  # n of group1\ngrp2n &lt;- 100  # n of group2\n\n# Calculate effect size\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and sd to effect size d\n    Effect Size:  -1.0000\n Standard Error:   0.1500\n       Variance:   0.0225\n       Lower CI:  -1.2940\n       Upper CI:  -0.7060\n         Weight:  44.4444\n\n\nTo conduct a meta-analysis of standardized mean differences, our data set should at least contain the following columns:\n\nn.e. The number of observations in the intervention/experimental group.\nmean.e. The mean of the intervention/experimental group.\nsd.e. The standard deviation in the intervention/experimental group.\nn.c. The number of observations in the control group.\nmean.c. The mean of the control group.\nsd.c. The standard deviation in the control group.\n\nFor binary outcomes odds ratios can be used. The esc_2x2 function in the esc package provides an easy way to calculate the (log) odds ratio in R.\n\nlibrary(esc)\n\n# Define data\ngrp1yes &lt;- 45  # events in the treatment group\ngrp1no &lt;- 98   # non-events in the treatment group\ngrp2yes &lt;- 67  # events in the control group\ngrp2no &lt;- 76   # non-events in the control group\n\n# Calculate OR by setting es.type to \"or\"\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n    Effect Size:   0.5209\n Standard Error:   0.2460\n       Variance:   0.0605\n       Lower CI:   0.3216\n       Upper CI:   0.8435\n         Weight:  16.5263\n\n\nTo conduct a meta-analysis of odds ratios in R, the following columns should be included in our data set:\n\nevent.e. The number of events in the treatment or experimental group.\n\nn.e. The sample size of the treatment or experimental group.\n\nevent.c. The number of events in the control group.\n\nn.c. The sample size of the control group.\n\nFor a practice sample for correction we look at small sample correction. We can easily convert unstandardized SMDs/Cohen’s dto Hedges’ g using the hedges_g function in the esc-package.\n\n# Load esc package\nlibrary(esc)\n\n# Define uncorrected SMD and sample size n\nSMD &lt;- 0.5\nn &lt;- 30\n\n# Convert to Hedges g\ng &lt;- hedges_g(SMD, n)\ng\n\n[1] 0.4864865"
  },
  {
    "objectID": "02-discovering_R.html#theorie",
    "href": "02-discovering_R.html#theorie",
    "title": "2  R ontdekken",
    "section": "2.1 Theorie",
    "text": "2.1 Theorie\nR is uitgegroeid tot een van de krachtigste en meest gebruikte statistische programmeertalen ter wereld. Of je nu in de academische wereld werkt of in een bedrijf, de dingen die je in R kunt doen lijken vaak een superkracht voor anderen. Maar het is een superkracht die iedereen kan leren, mits je er wat tijd en moeite in stot.\nHet boek laat zien hoe je R en RStudio installeert (de laatste geeft ons een gebruikersinterface die het makkelijker maakt om met onze gegevens, pakketten en uitvoer om te gaan). R is geen computerprogramma met een grafische gebruikersinterface en voorgedefinieerde functionaliteit. RStudio laat jou makkelijker met R werken. R is de moter en RStduio is meer het dashboard. Het boek laat zien hoe het met elkaar werkt.\nR is een volledige programmeertaal waaraan mensen over de hele wereld met vrij beschikbare uitbreidingen, zogenaamde specifieke pakketten, kunnen bijdragen. Belangrijke specifieke pakketten voor het werken met dit boek en het doen van meta-analyse met R zijn meta (zie bv hier), metafor(zie bv hier), dmetar (zie hier) en (voor data bewerking) tidyverse (zie hier.\nNadat je R en RStudio hebt geïnstalleerd op jouw computer, moet deze pakketten installeren op je computer. De fundamentele bouwstenen van R zijn functies, waarmee in dit hoofdstuk wordt gewerkt en waarmee je een goed idee krijgt hoe een en ander voor het uitvoeren van meta-analyses werkt. Veel van de functies kunnen worden geïmporteerd en uitgevoerd via pakketten die met internet zijn te installeren. Functies kunnen worden gebruikt om gegevens te importeren, te manipuleren, te transformeren en op te slaan met behulp van R. Er worden voorbeelden gegeven van basisfuncties die belangrijk zijn voor het uitvoeren van meta-analyses in R en in de hoofdstukken hierna worden uitgevoerd."
  },
  {
    "objectID": "02-discovering_R.html#practijk",
    "href": "02-discovering_R.html#practijk",
    "title": "2  Discovering R",
    "section": "2.2 Practijk",
    "text": "2.2 Practijk\nInstalleer eerst de pakketten die nodig zijn voor dit boek. Ik moest zelf een vorige versie van meta installeren om het pakket dmetar te installeren. Als je dit niet eerder hebt gedaan met je de hekjes (#) weghalen en de code uitvoeren. Dat installeren hoef je maar één keer te doen.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLaad de pakketten die nodig zijn om de voorbeelden in dit boek uit te voeren.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nHaal ook de datasetSuicidePrevention.xlx die je hier vandaan kunt halen en open die set.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLaten we naar die dataset kijken en zien welke variabelen er zijn. Er zijn tien kolommen (variabelen) en negen rijgen (individuele studies)\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nJe kunt de inhoud van een bepaalde kolommen alleen bekijken, bv deze:\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nEn je kunt ook zien wat voor een soort variabele het is.\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLaten we het gemiddelde van deze variabele vaststellen.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nZorg ervoor dat de variabelen de goede klasse hebben, bijvoorbeeld numeriek. Laten we dit veranderen voor enkele variabelen.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwee variabelen moeten we veranderen in factoren om de analyse later correct te kunnen uitvoeren.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn dit geval is de variabele age_group opgesplitst in de niveaus gen en older, zie hier:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nEen logische variabele kan ook handig zijn, bijvoorbeeld voor de volgende variabele:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\nDeze zetten we om in een logische variabele.\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSoms is het goed om naar specifieke gegevens uit het dataframe te kijken. Onthoud: data.frame[rijen, kolommen]. Dus kijken naar rij 2 wordt:\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nAls je informatie van de eerste kolom én de tweede rij wilt zien, schrijf je:\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nGebruik de functie c() om delen van het dataframe te selecteren. Om rijen 2 en 3 en kolommen 4 en 6 te extraheren wordt\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRijen selecteer je op nummer, kolommen kun je ook op naam selecteren, zoals in dit voorbeeld.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nJe kunt voor een gegevensverzameling ook de functie filter gebruiken, die werkt op basis van rijwaarden, bijvoorbeeld de rijwaarden van n.e. zijn kleiner of gelijk aan 50. Dan schrijf je:\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nJe kunt gegevens zelf gemakkelijk transformeren. Dus als je de studie van De Vries et al. wilt transformeren van 2019 naar 2018, kun je het schrijven als:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nAls je een nieuwe kolom wilt toevoegen aan je dataframe (bijvoorbeeld het gemiddelde verschil), kun je dat als volgt doen:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nZodra alles is getransformeerd, kunnen we het bewerkte bestand opslaan. Je kunt het opslaan als een .rda-bestand, zo dan:\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nof opslaan als een .csv-bestand, zo dan:\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\n\nBewaar je transformatie syntax, zodat je weet wat je hebt gedaan van de originele gegevens naar de uiteindelijke gegevens."
  },
  {
    "objectID": "02-discovering_R.html#praktijk",
    "href": "02-discovering_R.html#praktijk",
    "title": "2  R ontdekken",
    "section": "2.2 Praktijk",
    "text": "2.2 Praktijk\nInstalleer eerst de pakketten die nodig zijn voor dit boek. Ik moest zelf een vorige versie van meta installeren om het pakket dmetar te installeren. Als je dit niet eerder hebt gedaan met je de hekjes (#) weghalen en de code uitvoeren. Dat installeren hoef je maar één keer te doen.\n\n#require(remotes)\n#install_version(\"meta\", version = \"6.5.0\", repos = \"http://cran.us.r-project.org\")\n\n#install.packages(\"tidyverse\")\n\n#install.packages(\"metafor\")\n\n#install.packages(\"devtools\")\n\n#devtools::install_github(\"MathiasHarrer/dmetar\")\n\nLaad de pakketten die nodig zijn om de voorbeelden in dit boek uit te voeren.\n\nlibrary(meta)\n\nLoading 'meta' package (version 6.5-0).\nType 'help(meta)' for a brief overview.\nReaders of 'Meta-Analysis with R (Use R!)' should install\nolder version of 'meta' package: https://tinyurl.com/dt4y5drs\n\nlibrary(metafor)\n\nLoading required package: Matrix\n\n\nLoading required package: metadat\n\n\nLoading required package: numDeriv\n\n\n\nLoading the 'metafor' package (version 4.4-0). For an\nintroduction to the package please type: help(metafor)\n\nlibrary(dmetar)\n\nExtensive documentation for the dmetar package can be found at: \n www.bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::expand() masks Matrix::expand()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ tidyr::pack()   masks Matrix::pack()\n✖ tidyr::unpack() masks Matrix::unpack()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nHaal ook de datasetSuicidePrevention.xlx die je hier vandaan kunt halen en open die set.\n\nlibrary(openxlsx)\ndata &lt;-read.xlsx(\"SuicidePrevention.xlsx\")\n\nLaten we naar die dataset kijken en zien welke variabelen er zijn. Er zijn tien kolommen (variabelen) en negen rijgen (individuele studies)\n\nglimpse(SuicidePrevention)\n\nRows: 9\nColumns: 10\n$ author    &lt;chr&gt; \"Berry et al.\", \"DeVries et al.\", \"Fleming et al.\", \"Hunt & …\n$ n.e       &lt;dbl&gt; 90, 77, 30, 64, 50, 109, 60, 40, 51\n$ mean.e    &lt;dbl&gt; 14.98, 16.21, 3.01, 19.32, 4.54, 15.11, 3.44, 7.10, 23.74\n$ sd.e      &lt;dbl&gt; 3.29, 5.35, 0.87, 6.41, 2.75, 4.63, 1.26, 0.76, 7.24\n$ n.c       &lt;dbl&gt; 95, 69, 30, 65, 50, 111, 60, 40, 56\n$ mean.c    &lt;dbl&gt; 15.54, 20.13, 3.13, 20.22, 5.61, 16.46, 3.42, 7.38, 24.91\n$ sd.c      &lt;dbl&gt; 4.41, 7.43, 1.23, 7.62, 2.66, 5.39, 1.88, 1.41, 10.65\n$ pubyear   &lt;dbl&gt; 2006, 2019, 2006, 2011, 1997, 2000, 2013, 2015, 2014\n$ age_group &lt;fct&gt; gen, older, gen, gen, gen, gen, gen, older, older\n$ control   &lt;fct&gt; WLC, no intervention, no intervention, WLC, WLC, no interven…\n\n\nJe kunt de inhoud van een bepaalde kolommen alleen bekijken, bv deze:\n\nSuicidePrevention$n.e\n\n[1]  90  77  30  64  50 109  60  40  51\n\n\nEn je kunt ook zien wat voor een soort variabele het is.\n\nclass(SuicidePrevention$n.e)\n\n[1] \"numeric\"\n\n\nLaten we het gemiddelde van deze variabele vaststellen.\n\nmean(SuicidePrevention$n.e)\n\n[1] 63.44444\n\n\nZorg ervoor dat de variabelen de goede klasse hebben, bijvoorbeeld numeriek. Laten we dit veranderen voor enkele variabelen.\n\nSuicidePrevention$mean.e &lt;- as.numeric(SuicidePrevention$mean.e)\nSuicidePrevention$sd.e &lt;- as.numeric(SuicidePrevention$sd.e)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\nSuicidePrevention$mean.c &lt;- as.numeric(SuicidePrevention$mean.c)\nSuicidePrevention$sd.c &lt;- as.numeric(SuicidePrevention$sd.c)\nSuicidePrevention$n.c &lt;- as.numeric(SuicidePrevention$n.c)\n\nTwee variabelen moeten we veranderen in factoren om de analyse later correct te kunnen uitvoeren.\n\nSuicidePrevention$age_group &lt;- as.factor(SuicidePrevention$age_group)\nSuicidePrevention$control &lt;- as.factor(SuicidePrevention$control)\n\nIn dit geval is de variabele age_group opgesplitst in de niveaus gen en older, zie hier:\n\nSuicidePrevention$age_group\n\n[1] gen   older gen   gen   gen   gen   gen   older older\nLevels: gen older\n\n\nEen logische variabele kan ook handig zijn, bijvoorbeeld voor de volgende variabele:\n\nSuicidePrevention$pubyear\n\n[1] 2006 2019 2006 2011 1997 2000 2013 2015 2014\n\n\nDeze zetten we om in een logische variabele.\n\nas.logical(SuicidePrevention$pubyear &gt;= 2010)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE\n\n\nSoms is het goed om naar specifieke gegevens uit het dataframe te kijken. Onthoud: data.frame[rijen, kolommen]. Dus kijken naar rij 2 wordt:\n\nSuicidePrevention[2,]\n\n          author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n2 DeVries et al.  77  16.21 5.35  69  20.13 7.43    2019     older\n          control\n2 no intervention\n\n\nAls je informatie van de eerste kolom én de tweede rij wilt zien, schrijf je:\n\nSuicidePrevention[2,1]\n\n[1] \"DeVries et al.\"\n\n\nGebruik de functie c() om delen van het dataframe te selecteren. Om rijen 2 en 3 en kolommen 4 en 6 te extraheren wordt\n\nSuicidePrevention[c(2,3),c(4,6)]\n\n  sd.e mean.c\n2 5.35  20.13\n3 0.87   3.13\n\n\nRijen selecteer je op nummer, kolommen kun je ook op naam selecteren, zoals in dit voorbeeld.\n\nSuicidePrevention[, c(\"author\", \"control\")]\n\n           author         control\n1    Berry et al.             WLC\n2  DeVries et al. no intervention\n3  Fleming et al. no intervention\n4    Hunt & Burke             WLC\n5 McCarthy et al.             WLC\n6   Meijer et al. no intervention\n7   Rivera et al. no intervention\n8  Watkins et al. no intervention\n9  Zaytsev et al. no intervention\n\n\nJe kunt voor een gegevensverzameling ook de functie filter gebruiken, die werkt op basis van rijwaarden, bijvoorbeeld de rijwaarden van n.e. zijn kleiner of gelijk aan 50. Dan schrijf je:\n\nfilter(SuicidePrevention, n.e &lt;= 50)\n\n           author n.e mean.e sd.e n.c mean.c sd.c pubyear age_group\n1  Fleming et al.  30   3.01 0.87  30   3.13 1.23    2006       gen\n2 McCarthy et al.  50   4.54 2.75  50   5.61 2.66    1997       gen\n3  Watkins et al.  40   7.10 0.76  40   7.38 1.41    2015     older\n          control\n1 no intervention\n2             WLC\n3 no intervention\n\n\nJe kunt gegevens zelf gemakkelijk transformeren. Dus als je de studie van De Vries et al. wilt transformeren van 2019 naar 2018, kun je het schrijven als:\n\nSuicidePrevention[2, \"pubyear\"] &lt;- 2018\nSuicidePrevention[2, \"pubyear\"]\n\n[1] 2018\n\n\nAls je een nieuwe kolom wilt toevoegen aan je dataframe (bijvoorbeeld het gemiddelde verschil), kun je dat als volgt doen:\n\nSuicidePrevention$md &lt;- SuicidePrevention$mean.e - SuicidePrevention$mean.c\n\nZodra alles is getransformeerd, kunnen we het bewerkte bestand opslaan. Je kunt het opslaan als een .rda-bestand, zo dan:\n\nsave(SuicidePrevention, file = \"SuicidePrevention.rda\")\n\nof opslaan als een .csv-bestand, zo dan:\n\nwrite.csv(SuicidePrevention, file = \"SuicidePrevention.csv\")\n\n\n\n\n\n\n\nImportant\n\n\n\nBewaar je transformatie syntax, zodat je weet wat je hebt gedaan van de originele gegevens naar de uiteindelijke gegevens."
  },
  {
    "objectID": "03-effect_sizes.html#theorie",
    "href": "03-effect_sizes.html#theorie",
    "title": "3  Effect Sizes",
    "section": "3.1 Theorie",
    "text": "3.1 Theorie\nEffect size wordt hier gedefinieerd als een metriek die de relatie tussen twee entiteiten kwantificeert. Het geeft de richting en sterkte van deze relatie weer. Als relaties worden uitgedrukt in een vergelijkbare effect size, is het mogelijk om ze te vergelijken. Effect sizes zijn de bouwstenen van meta-analyses.Om een meta-analyse uit te voeren, is op zijn minst een schatting nodig van de effect size en de standaard-fout ervan. Deze moeten vergelijkbaar, berekenbaar, betrouwbaar en interpreteerbaar zijn. De standaard-fout van een effect size geeft aan hoe nauwkeurig de schatting van het effect van de studie is. Meta-analyse geeft effect-sizes met een grotere precisie een hoger gewicht omdat ze betere schatters zijn van het ware effect.\nEr zijn verschillende effectmaten die we kunnen gebruiken in meta-analyses. Gebruikelijke zijn “één-variabele” relatiematen, zoals:\n- gemiddelden (som van alle individuele waarden, gedeeld door de som van de steekproefgrootte);\n- proporties (aantal individuen dat in een specifieke subgroep valt, gedeeld door het totale aantal individuen);\n- correlaties (drukt de mate van co-variatie tussen twee variabelen uit, bijvoorbeeld de Pearson Product-Moment Correlatie en Point-Biserial Correlatie);\n- risicoverhouding (relatief risico) als de verhouding tussen twee risico’s;\n- odds ratio, als het aantal gevallen dat in een bepaalde subgroep valt, gedeeld door het aantal gevallen dat niet in die subgroep valt;\n- incidentieratio’s (ook wel rate ratio genoemd), houdt rekening met de persoon/tijd-aspecten van twee groepen.\nEffectgroottes kunnen ook vertekend zijn, bijvoorbeeld door meetfouten en bereikbeperking. Er bestaan formules om te corrigeren voor sommige vertekeningen, waaronder de kleine steekproefvertekening van gestandaardiseerde gemiddelde verschillen, verzwakking door onbetrouwbaarheid en problemen met bereikbeperking. Andere veel voorkomende problemen zijn dat studies de gegevens die nodig zijn om effectgroottes te berekenen in verschillende formaten rapporteren, evenals het probleem van de analyse-eenheid, dat optreedt wanneer studies meer dan één effect size bijdragen."
  },
  {
    "objectID": "03-effect_sizes.html#praktijk",
    "href": "03-effect_sizes.html#praktijk",
    "title": "3  Effect Sizes",
    "section": "3.2 Praktijk",
    "text": "3.2 Praktijk\nLaten we eerst kijken naar de gestandaardiseerde size van het verschil tussen groepen (SMD). Deze wordt gebruikt als de uitkomst continu is en de voorspeller categorisch. Het is het verschil in gemiddelden tussen twee onafhankelijke groepen gedeeld door de gepoolde standaardafwijking. Het wordt ook Cohen’s \\(d\\) genoemd.\n\\[SMD_{between} = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p}\\]\nwaarbij \\(\\bar{X}_1\\) en \\(\\bar{X}_2\\) de gemiddelden van de twee groepen zijn en \\(s_p\\) de gepoolde standaardafwijking. SMD’s worden vaak geïnterpreteerd als kleine (0,2), middelgrote (0,5) en grote (0,8) effecten. Er zijn verschillende functies in R waarmee we SMDbetween/Cohen’s d in één stap kunnen berekenen. Hier gebruiken we de functie esc_mean_sd, die deel uitmaakt van het esc-pakket. We hebben dit pakket nog niet eerder gebruikt, dus het is noodzakelijk om het eerst te installeren.\n\n# install.packages(\"esc\")\nlibrary(esc)\n\n# Defineeer data die nodig zijn om SMD/d te berekenen\n# Dit is een eenvoudig voorbeeld om een dataset te maken\ngrp1m &lt;- 50   # gemiddelde van groep 1\ngrp2m &lt;- 60   # gemiddelde van groep 2\ngrp1sd &lt;- 10  # sd van groep 1\ngrp2sd &lt;- 10  # sd van groep 2\ngrp1n &lt;- 100  # n van groep 1 \ngrp2n &lt;- 100  # n van groep 2\n\n# CalculEER effect size\nesc_mean_sd(grp1m = grp1m, grp2m = grp2m, \n            grp1sd = grp1sd, grp2sd = grp2sd, \n            grp1n = grp1n, grp2n = grp2n)\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: mean and sd to effect size d\n    Effect Size:  -1.0000\n Standard Error:   0.1500\n       Variance:   0.0225\n       Lower CI:  -1.2940\n       Upper CI:  -0.7060\n         Weight:  44.4444\n\n\nOm een meta-analyse van gestandaardiseerde gemiddelde verschillen uit te voeren, moet onze dataset ten minste de volgende kolommen bevatten:\n\nn.e. Het aantal observaties in de interventie/experimentele groep.\n\nmean.e. Het gemiddelde van de interventie/experimentele groep.\n\nsd.e. De standaardafwijking in de interventie/experimentele groep.\n\nn.c. Het aantal observaties in de controlegroep.\n\nmean.c. Het gemiddelde van de controlegroep.\n\nsd.c. De standaardafwijking in de controlegroep.\n\nVoor binaire uitkomsten kunnen kansverhoudingen worden gebruikt. De functie esc_2x2 in het pakket esc biedt een eenvoudige manier om de (log)odds ratio in R te berekenen.\n\nlibrary(esc)\n\n# Defineeer data die nodig zijn om de odds ratio te berekenen\ngrp1yes &lt;- 45  # gebeurtenissen in de behandelingsgroep\ngrp1no &lt;- 98   # niet-gebeurtenissen in de behandelingsgroep\ngrp2yes &lt;- 67  # gebeurtenissen in de controlegroep\ngrp2no &lt;- 76   # niet-gebeurtenissen in de controlegroep\n\n# Calculeer OR door es.type op \"or\" te zetten\nesc_2x2(grp1yes = grp1yes, grp1no = grp1no,\n        grp2yes = grp2yes, grp2no = grp2no,\n        es.type = \"or\")\n\n\nEffect Size Calculation for Meta Analysis\n\n     Conversion: 2x2 table (OR) coefficient to effect size odds ratio\n    Effect Size:   0.5209\n Standard Error:   0.2460\n       Variance:   0.0605\n       Lower CI:   0.3216\n       Upper CI:   0.8435\n         Weight:  16.5263\n\n\nOm een meta-analyse van odds ratio’s uit te voeren in R, moeten de volgende kolommen worden opgenomen in onze dataset:\n\nevent.e. Het aantal geberutenissen in de experimentele groep.\nn.e. De sample size van de experimentele groep.\n\nevent.c. Het aantal gebeurtenissen in de controle groep.\n\nn.c. De sample size van de controle groep.\n\nVoor een voorbeeld voor correctie kijken we naar kleine steekproefcorrectie. We kunnen niet-gestandaardiseerde SMD’s/Cohen’s d eenvoudig omzetten naar Hedges’ g met behulp van de hedges_g functie in het esc pakket.\n\n# Laad esc pakket\nlibrary(esc)\n\n# Defineer niet aangepast SMD en sample size n\nSMD &lt;- 0.5\nn &lt;- 30\n\n# Zet om naar Hedges g\ng &lt;- hedges_g(SMD, n)\ng\n\n[1] 0.4864865"
  }
]